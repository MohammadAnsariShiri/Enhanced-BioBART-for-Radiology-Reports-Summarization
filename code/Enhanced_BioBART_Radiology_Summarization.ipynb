{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaIuPOSyCqdJ",
        "outputId": "5d847697-f70e-4f8c-ea94-0ae20fa82252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: py-rouge in /usr/local/lib/python3.11/dist-packages (1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scispacy in /usr/local/lib/python3.11/dist-packages (0.5.5)\n",
            "Requirement already satisfied: negspacy in /usr/local/lib/python3.11/dist-packages (1.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from scispacy) (3.7.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from scispacy) (1.15.3)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.11/dist-packages (from scispacy) (6.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from scispacy) (1.6.1)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.11/dist-packages (from scispacy) (0.3.4)\n",
            "Requirement already satisfied: nmslib-metabrainz==2.1.3 in /usr/local/lib/python3.11/dist-packages (from scispacy) (2.1.3)\n",
            "Requirement already satisfied: pybind11>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from nmslib-metabrainz==2.1.3->scispacy) (2.13.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from nmslib-metabrainz==2.1.3->scispacy) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.3->scispacy) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->scispacy) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->scispacy) (0.4.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->scispacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->scispacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->scispacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->scispacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->scispacy) (0.1.2)\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_lg-0.5.4.tar.gz\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_lg-0.5.4.tar.gz (531.2 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from en_core_sci_lg==0.5.4) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2025.4.26)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_lg==0.5.4) (0.1.2)\n",
            "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# (Cell 1) Install Libraries\n",
        "\n",
        "!pip install nltk rouge-score py-rouge transformers tqdm datasets evaluate scispacy negspacy\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_lg-0.5.4.tar.gz\n",
        "! python -m nltk.downloader punkt stopwords\n",
        "! pip install rouge_score evaluate\n",
        "! pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LonDEIL9c5y",
        "outputId": "5ff6de6c-e788-4e73-9ed4-4c0c9494d2d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading scispaCy model for clinical evaluation ---\n",
            "SpaCy version being used by script: 3.7.5\n",
            "Could not get spaCy data path: cannot import name 'get_data_path' from 'spacy.util' (/usr/local/lib/python3.11/dist-packages/spacy/util.py)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
            "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scispaCy model 'en_core_sci_lg' loaded successfully.\n",
            "Target entity types for clinical evaluation: {'TREATMENT', 'PROBLEM', 'ENTITY', 'TEST'}\n",
            "\n",
            "Setting up ROUGE and BLEU scorers...\n"
          ]
        }
      ],
      "source": [
        "# (Cell 2) Import Modules\n",
        "# Import core libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration # Using BART model\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm # Use auto version for better notebook integration\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # For TF-IDF target generation\n",
        "import gc  # Garbage collector\n",
        "import os\n",
        "import json\n",
        "import re # For section parsing\n",
        "import time # For runtime tracking\n",
        "import random # For selecting qualitative examples\n",
        "from torch.cuda.amp import autocast, GradScaler # For Mixed Precision Training\n",
        "from collections import Counter\n",
        "import evaluate\n",
        "\n",
        "# --- spaCy / scispaCy / negspacy Imports (for Clinical Metrics) ---\n",
        "import spacy\n",
        "import scispacy # Required for loading sci models\n",
        "# Optional: for advanced negation detection - uncomment if used\n",
        "# from negspacy.negation import Negex\n",
        "\n",
        "\n",
        "# --- Download NLTK resources ---\n",
        "# Download necessary NLTK data for tokenization and stop words\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    print(\"Downloading NLTK punkt tokenizer...\")\n",
        "    nltk.download('punkt', quiet=True)\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except nltk.downloader.DownloadError:\n",
        "    print(\"Downloading NLTK stopwords...\")\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Download punkt_tab for sentence tokenization if needed (TF-IDF)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt/english.pickle')\n",
        "except nltk.downloader.DownloadError:\n",
        "     print(\"Downloading NLTK punkt_tab for sentence tokenization...\")\n",
        "     nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "\n",
        "# --- Load spaCy and scispaCy model ---\n",
        "# Initialize flags\n",
        "SCISPACY_LOADED = False\n",
        "TARGET_ENTITY_TYPES = set() # Set to empty initially\n",
        "nlp_sci = None # Initialize nlp_sci model\n",
        "\n",
        "print(\"\\n--- Loading scispaCy model for clinical evaluation ---\")\n",
        "print(f\"SpaCy version being used by script: {spacy.__version__}\")\n",
        "try:\n",
        "    from spacy.util import get_data_path\n",
        "    print(f\"SpaCy data path being used by script: {get_data_path()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not get spaCy data path: {e}\")\n",
        "\n",
        "try:\n",
        "    # Using the large model for potentially better entity recognition\n",
        "    # Ensure en_core_sci_lg model v0.5.4 is installed and compatible with your spaCy version\n",
        "    nlp_sci = spacy.load(\"en_core_sci_lg\")\n",
        "    # Optional: Add negspacy component if you want to explore negation later\n",
        "    # nlp_sci.add_pipe(\"negex\", config={\"ent_types\":list(TARGET_ENTITY_TYPES)}) # Ensure types match\n",
        "    print(\"scispaCy model 'en_core_sci_lg' loaded successfully.\")\n",
        "    SCISPACY_LOADED = True\n",
        "    # Define target entity types for clinical evaluation (adjust as needed)\n",
        "    TARGET_ENTITY_TYPES = {\"PROBLEM\", \"TREATMENT\", \"TEST\", \"ENTITY\"}\n",
        "    print(f\"Target entity types for clinical evaluation: {TARGET_ENTITY_TYPES}\")\n",
        "\n",
        "except OSError:\n",
        "    print(\"Error: scispaCy model 'en_core_sci_lg' not found or incompatible.\")\n",
        "    print(\"Please ensure it is installed correctly and compatible with your spaCy version.\")\n",
        "    print(\"Refer to scispaCy documentation for installation instructions: https://allenai.github.io/scispacy/\")\n",
        "    SCISPACY_LOADED = False\n",
        "    TARGET_ENTITY_TYPES = set() # Set to empty if model not loaded\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred while loading scispaCy model: {e}\")\n",
        "    SCISPACY_LOADED = False\n",
        "    TARGET_ENTITY_TYPES = set()\n",
        "\n",
        "\n",
        "# --- Evaluation Metric Scorers ---\n",
        "# Initialize ROUGE and BLEU scorers\n",
        "print(\"\\nSetting up ROUGE and BLEU scorers...\")\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "smoother = SmoothingFunction().method1 # For BLEU smoothing\n",
        "\n",
        "# Clean up memory after imports and initial setup\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmdeBI2i9l9N",
        "outputId": "4125cc89-53c2-4186-e06e-0a7f4cf14e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory: /content/drive/MyDrive/BioBart_TFIDF_Structured\n",
            "Section special tokens defined: ['[TECHNIQUE_SEP]', '[REASON_SEP]', '[FINDINGS_SEP]', '[IMPRESSION_SEP]', '[CONCLUSION_SEP]', '[INDICATION_SEP]']\n",
            "Length control tokens defined: ['<SUM_SHORT>', '<SUM_MEDIUM>', '<SUM_LONG>']\n",
            "Effective batch size: 64\n",
            "\n",
            "Saving training configuration to /content/drive/MyDrive/BioBart_TFIDF_Structured/training_config.json...\n",
            "Configuration saved.\n"
          ]
        }
      ],
      "source": [
        "# (Cell 3) Configuration and Paths\n",
        "\n",
        "# --- Configuration ---\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED) # Seed for random sample selection\n",
        "tqdm.pandas() # Enable progress bars for pandas apply\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! unzip /content/drive/MyDrive/mimic-iii-10k.zip -d /content/datasetA\n",
        "\n",
        "# --- Paths ---\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/BioBart_Radiology_Summarization\" # Define your base drive path\n",
        "CHECKPOINT_DIR = os.path.join(DRIVE_PATH, \"checkpoints\")\n",
        "METRICS_FILE = os.path.join(DRIVE_PATH, \"training_metrics.json\")\n",
        "FINAL_RESULTS_FILE = os.path.join(DRIVE_PATH, \"final_results.json\")\n",
        "TOKENIZER_PATH = os.path.join(DRIVE_PATH, \"tokenizer\") # Path to save/load custom tokenizer\n",
        "FINAL_MODEL_PATH = os.path.join(DRIVE_PATH, \"complete_model\") # Path to save final model\n",
        "CONFIG_FILE = os.path.join(DRIVE_PATH, \"training_config.json\") # Path for configuration file\n",
        "QUALITATIVE_EXAMPLES_FILE = os.path.join(DRIVE_PATH, \"qualitative_examples.json\") # Path for qualitative examples\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "print(f\"Working directory: {DRIVE_PATH}\")\n",
        "\n",
        "\n",
        "# --- Data Parameters ---\n",
        "DATA_PATH = '/content/datasetA/MIMIC -III (10000 patients)/NOTEEVENTS/NOTEEVENTS_sorted.csv' # Path to your MIMIC-III data\n",
        "SAMPLE_SIZE = 104995 # Number of radiology reports to sample from the full dataset\n",
        "min_word_count = 50 # Minimum word count for an original report to be included\n",
        "max_word_count = 1024 # Maximum word count for the original report (truncate if longer)\n",
        "tfidf_ratio = 0.3 # Ratio of sentences to select for TF-IDF extractive summary\n",
        "\n",
        "\n",
        "# --- Special Tokens Definition ---\n",
        "# Section Headers found in reports and corresponding special tokens\n",
        "SECTION_HEADERS = {\n",
        "    \"INDICATION\": [\"[INDICATION_SEP]\", \"[REASON_SEP]\"],\n",
        "    \"TECHNIQUE\": [\"[TECHNIQUE_SEP]\"],\n",
        "    \"FINDINGS\": [\"[FINDINGS_SEP]\"],\n",
        "    \"IMPRESSION\": [\"[IMPRESSION_SEP]\", \"[CONCLUSION_SEP]\"]\n",
        "}\n",
        "# Regex to find any of the defined headers for parsing\n",
        "ALL_HEADERS_REGEX = \"|\".join([h.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"_SEP\",\"\") for sl in SECTION_HEADERS.values() for h in sl])\n",
        "# List of unique section special tokens\n",
        "SECTION_SPECIAL_TOKENS = list(set([token for sublist in SECTION_HEADERS.values() for token in sublist]))\n",
        "print(f\"Section special tokens defined: {SECTION_SPECIAL_TOKENS}\")\n",
        "\n",
        "# Length Control Tokens based on target summary word count\n",
        "LENGTH_CONTROL_TOKENS = [\"<SUM_SHORT>\", \"<SUM_MEDIUM>\", \"<SUM_LONG>\"]\n",
        "# Thresholds for defining short, medium, long summaries (in words)\n",
        "short_threshold = 50\n",
        "medium_threshold = 100\n",
        "print(f\"Length control tokens defined: {LENGTH_CONTROL_TOKENS}\")\n",
        "\n",
        "# All new tokens to be added to the tokenizer vocabulary\n",
        "ALL_NEW_SPECIAL_TOKENS = list(set(SECTION_SPECIAL_TOKENS + LENGTH_CONTROL_TOKENS))\n",
        "\n",
        "\n",
        "# --- Model and Training Parameters ---\n",
        "model_name = \"GanjinZero/biobart-v2-base\" # Pre-trained BART model\n",
        "MAX_INPUT_LENGTH = 512  # Max token length for model input (includes control + section tokens + text)\n",
        "MAX_TARGET_LENGTH = 150 # Max token length for model output (TF-IDF target summary)\n",
        "\n",
        "INITIAL_LR = 2e-5 # Initial learning rate for the optimizer\n",
        "num_epochs = 15 # Total number of training epochs\n",
        "batch_size = 8 # Batch size per GPU/device\n",
        "gradient_accumulation_steps = 8 # Number of batches to accumulate gradients over\n",
        "effective_batch_size = batch_size * gradient_accumulation_steps\n",
        "print(f\"Effective batch size: {effective_batch_size}\")\n",
        "\n",
        "# Progressive Unfreezing Schedule: Define which layers to unfreeze at which epoch\n",
        "# Note: Epoch numbers are 0-indexed here, but in training logs they are +1 (1-indexed)\n",
        "progressive_unfreezing_schedule = {\n",
        "    3: \"unfreeze_all_decoder\", # Example: Unfreeze all decoder layers at epoch 3\n",
        "    8: \"unfreeze_half_encoder\" # Example: Unfreeze top half of encoder layers at epoch 8\n",
        "    # Add more epochs and layers as needed\n",
        "}\n",
        "# Initial freezing happens after loading the base model and resizing embeddings\n",
        "# Default: Unfreeze shared embeddings, lm_head, and the last N decoder layers\n",
        "num_decoder_layers_to_unfreeze_initial = 4 # Number of decoder layers to unfreeze initially\n",
        "\n",
        "\n",
        "# Curriculum Learning Schedule: Define how the training data size increases\n",
        "curriculum_learning_schedule = {\n",
        "    \"initial_size\": 20000, # Initial number of training samples\n",
        "    \"increment\": 10000, # Number of samples to add per phase\n",
        "    \"increment_every_epochs\": 3 # Number of epochs per phase\n",
        "}\n",
        "\n",
        "\n",
        "# --- Generation Parameters for Validation and Testing ---\n",
        "# These parameters control the beam search during model.generate()\n",
        "generation_parameters = {\n",
        "    \"max_length\": MAX_TARGET_LENGTH + 10, # Maximum length of generated summary\n",
        "    \"num_beams\": 4, # Number of beams for beam search\n",
        "    \"length_penalty\": 1.0, # Encourages longer summaries if > 1.0, shorter if < 1.0\n",
        "    \"early_stopping\": True, # Stop beam search when all beams have generated an EOS token\n",
        "    \"no_repeat_ngram_size\": 3 # Avoids repeating n-grams of this size\n",
        "}\n",
        "\n",
        "\n",
        "# --- Configuration Dictionary (for saving) ---\n",
        "training_config = {\n",
        "    \"seed\": SEED,\n",
        "    \"drive_path\": DRIVE_PATH,\n",
        "    \"data_path\": DATA_PATH,\n",
        "    \"model_name\": model_name,\n",
        "    \"sample_size\": SAMPLE_SIZE,\n",
        "    \"min_word_count\": min_word_count,\n",
        "    \"max_word_count\": max_word_count,\n",
        "    \"tfidf_ratio\": tfidf_ratio,\n",
        "    \"section_headers\": SECTION_HEADERS,\n",
        "    \"length_control_tokens\": LENGTH_CONTROL_TOKENS,\n",
        "    \"length_control_thresholds\": {\"short\": short_threshold, \"medium\": medium_threshold},\n",
        "    \"all_new_special_tokens\": ALL_NEW_SPECIAL_TOKENS,\n",
        "    \"max_input_length\": MAX_INPUT_LENGTH,\n",
        "    \"max_target_length\": MAX_TARGET_LENGTH,\n",
        "    \"initial_lr\": INITIAL_LR,\n",
        "    \"num_epochs\": num_epochs,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "    \"effective_batch_size\": effective_batch_size,\n",
        "    \"initial_unfrozen_decoder_layers\": num_decoder_layers_to_unfreeze_initial,\n",
        "    \"progressive_unfreezing_schedule\": progressive_unfreezing_schedule,\n",
        "    \"curriculum_learning_schedule\": curriculum_learning_schedule,\n",
        "    \"generation_parameters\": generation_parameters,\n",
        "    \"evaluation_entity_types\": list(TARGET_ENTITY_TYPES) if TARGET_ENTITY_TYPES else [], # Ensure serializable\n",
        "    \"scispacy_model\": \"en_core_sci_lg\",\n",
        "    \"scispacy_loaded\": SCISPACY_LOADED # Record if scispaCy was loaded\n",
        "}\n",
        "\n",
        "# Save the configuration\n",
        "print(f\"\\nSaving training configuration to {CONFIG_FILE}...\")\n",
        "try:\n",
        "    with open(CONFIG_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(training_config, f, ensure_ascii=False, indent=4)\n",
        "    print(\"Configuration saved.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving configuration: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gwOVRdMt9mQx"
      },
      "outputs": [],
      "source": [
        "# (Cell 4) Utility Functions (Preprocessing Helpers)\n",
        "\n",
        "# Function to add section tokens\n",
        "def add_section_tokens(text, section_headers_map=SECTION_HEADERS, all_headers_regex=ALL_HEADERS_REGEX):\n",
        "    \"\"\"Parses report text and inserts section-specific special tokens.\"\"\"\n",
        "    if not text or not all_headers_regex: return text\n",
        "    processed_text = text\n",
        "    # Regex to find section headers, handling variations and start of line/document\n",
        "    pattern = re.compile(r\"(?:^|\\\\n\\\\s*)(\" + all_headers_regex + r\")\\\\s*:?\\\\s*\", re.IGNORECASE)\n",
        "    last_match_end = 0\n",
        "    modified_parts = []\n",
        "    try:\n",
        "        for match in pattern.finditer(text):\n",
        "            header_found = match.group(1).upper() # Get the matched header text\n",
        "            match_start = match.start(1) # Start position of the matched header text\n",
        "            special_token = None\n",
        "            # Find the corresponding special token for the matched header\n",
        "            for canonical, tokens in section_headers_map.items():\n",
        "                # Create header names from the tokens in the map for matching\n",
        "                headers_in_map = [h.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"_SEP\",\"\") for h in tokens]\n",
        "                if header_found in headers_in_map:\n",
        "                    special_token = tokens[0] # Use the first token in the list as the main one\n",
        "                    break\n",
        "\n",
        "            if special_token:\n",
        "                # Add text before the header, the special token, and a space\n",
        "                modified_parts.append(text[last_match_end:match_start])\n",
        "                modified_parts.append(special_token + \" \")\n",
        "                last_match_end = match.end(0) # Update the end position to the end of the full match (header + colon/space)\n",
        "\n",
        "        # Add the remaining text after the last match\n",
        "        modified_parts.append(text[last_match_end:])\n",
        "\n",
        "        processed_text = \"\".join(modified_parts)\n",
        "        processed_text = ' '.join(processed_text.split()) # Normalize whitespace\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error during section token insertion - {e}. Returning original text.\")\n",
        "        return text # Return original text on error\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "\n",
        "# Function for TF-IDF Extractive Summary\n",
        "def create_extractive_summary_tfidf(text, ratio=0.3):\n",
        "    \"\"\"Creates an extractive summary using TF-IDF.\"\"\"\n",
        "    if not text or len(text.split()) < min_word_count: # Use same threshold as original data filtering\n",
        "        return text # Return original text if too short\n",
        "\n",
        "    try:\n",
        "        # Use NLTK's punkt for sentence tokenization\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "        if len(sentences) <= 3: # Handle very short texts or texts with few sentences\n",
        "            num_sentences = max(1, int(len(sentences) * ratio))\n",
        "            return ' '.join(sentences[:num_sentences])\n",
        "\n",
        "        # Use scikit-learn's default English stop words\n",
        "        tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "\n",
        "        # Calculate sentence scores by summing TF-IDF values\n",
        "        sentence_scores = np.array(tfidf_matrix.sum(axis=1)).flatten()\n",
        "\n",
        "        # Get indices of top sentences based on score\n",
        "        num_sentences = max(1, int(len(sentences) * ratio))\n",
        "        # Use argsort to get indices of sorted scores, take the top ones\n",
        "        top_sentence_indices = sentence_scores.argsort()[-num_sentences:]\n",
        "        # Sort indices to maintain original order of sentences in the summary\n",
        "        top_sentence_indices = sorted(top_sentence_indices)\n",
        "\n",
        "        summary = ' '.join([sentences[i] for i in top_sentence_indices])\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        # Fallback to taking the first few sentences on error\n",
        "        print(f\"Warning: TF-IDF summarization failed - {e}. Returning first sentences.\")\n",
        "        try:\n",
        "             sentences = sent_tokenize(text)\n",
        "             num_sentences = max(1, int(len(sentences) * ratio))\n",
        "             return ' '.join(sentences[:num_sentences])\n",
        "        except:\n",
        "             # Final fallback: return original text if short, else empty\n",
        "             return text if len(text.split()) < min_word_count else \"\"\n",
        "\n",
        "\n",
        "# Function to get length control token based on target summary word count\n",
        "def get_length_control_token(target_summary_text, short_threshold=short_threshold, medium_threshold=medium_threshold):\n",
        "    \"\"\"Determines length control token based on target summary word count.\"\"\"\n",
        "    word_count = len(str(target_summary_text).split()) # Ensure it's a string\n",
        "    if word_count <= short_threshold: return \"<SUM_SHORT>\"\n",
        "    elif word_count <= medium_threshold: return \"<SUM_MEDIUM>\"\n",
        "    else: return \"<SUM_LONG>\"\n",
        "\n",
        "# Text normalization for evaluation\n",
        "def normalize_text(text):\n",
        "    \"\"\"Normalizes text for consistent ROUGE/BLEU evaluation.\"\"\"\n",
        "    if not text: return \"\" # Return empty string for empty input\n",
        "    # Convert to lower case and strip whitespace\n",
        "    text = str(text).lower().strip() # Ensure string type\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "ec7b1af1152343779c90f54bd2282d16",
            "8a1fea910afb4313be0983b9d804bd17",
            "393fafede89246d3a7d6777becf5416e",
            "db19c56364204bd590230adb7107f17b",
            "406f9661028e4c2b8156efaa52c5f095",
            "3172cb6ac6624203a2d69848db609d7c",
            "a97c67e68e4a4544a0d89a932fa4dd87",
            "6b10b6d09809423c923fbbfae74f8e5c",
            "8bb56b5ee7304a2c9474644679d178de",
            "19453ff4e85541d29f0b8330d58f5567",
            "9a342f909c8d4844a389f0bcade1606a",
            "0f714bdc18d34e2382aff9860f04292c",
            "5c004c7d7aaa4a84b1749d651d0260e9",
            "d58d328cc3a74bef8d8493b947902d21",
            "107fff78e068443ca55f28b35c2649b2",
            "2530011ec3584100beacb2d43891f77b",
            "95be3333d1d54976a0f6e93713591de2",
            "1b645951eab649d9bf4357a70fe24921",
            "b0d89b9b30a0467c8557db0889b089c3",
            "a515449b26cf4cbd95b99c5a351a5cf4",
            "4f01842412e24e09a7858efddfac504d",
            "b62b4f5ee44e43c6a1baeeebc1450160",
            "e098ce4026ab4df186bd2551af8e3047",
            "fb75e5a900f34bdb997a22be3557183b",
            "89c8be812473417caf9532eaaa052395",
            "2d38a2dcbafd42a4af8605433260f51c",
            "eb38bb5ffdeb438a8a6969fd892d359b",
            "16f2cbfc4d2747a6818a66b558c82e38",
            "91a07466694747f49a7ca92c42613e1e",
            "283e700a6f9641eda3982e79c5fea687",
            "afe8bc2824e44c38bf9337e4192a8263",
            "a94100f7465042cc9c7260160b0ef9d5",
            "456993ba73714e5fa05fa4b116cb51ea",
            "350530365d434fb5a6f4db62e77a70e3",
            "71abcce11e7647d5801f7e0acad9ba8d",
            "f4dbf7f0ce3d45a2bbcd3a8a6492a8b6",
            "38f46293d00342578dcaa8341e62a41f",
            "6e4fc5c5034448ea8aa1e570a30b4e5a",
            "959ecb1a3f1c42a5a7542d2e51eec7cc",
            "191e47eeaf2840fa8e0c918d36a35f21",
            "7c120cee1d80437d841958069d179d95",
            "976b24bf3d534b78b69d4c55e002559e",
            "fd9d16952cdf41a38bce35d199df3975",
            "be388223ce8a40d392a570cbc7d434d6"
          ]
        },
        "id": "56NsUf759t77",
        "outputId": "90cce3a5-8029-4075-8029-f82b3464f60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n",
            "Loaded data from /content/datasetA/MIMIC -III (10000 patients)/NOTEEVENTS/NOTEEVENTS_sorted.csv\n",
            "Filtered 104995 Radiology reports.\n",
            "Selected 104995 Radiology samples for processing.\n",
            "Cleaning text and applying initial word count filters...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/104995 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec7b1af1152343779c90f54bd2282d16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 212 samples shorter than 50 words.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/104783 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f714bdc18d34e2382aff9860f04292c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncated texts longer than 1024 words.\n",
            "Generating TF-IDF target summaries ('target_text') with ratio 0.3...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/104783 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e098ce4026ab4df186bd2551af8e3047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding section tokens to original text ('section_aware_text')...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/104783 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "350530365d434fb5a6f4db62e77a70e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Determining length control tokens ('control_token') based on target summary word count (thresholds: short<=50, medium<=100)...\n",
            "Creating final input text ('input_text') by prepending control token...\n",
            "Removed 0 samples with empty targets/inputs after processing.\n",
            "Splitting data into Train, Validation, and Test sets...\n",
            "Train set size: 73348\n",
            "Validation set size: 15717\n",
            "Test set size: 15718\n"
          ]
        }
      ],
      "source": [
        "# (Cell 5) Data Loading and Preprocessing\n",
        "\n",
        "print(\"Loading and preprocessing data...\")\n",
        "\n",
        "try:\n",
        "    # Load data from the specified path\n",
        "    data = pd.read_csv(DATA_PATH)\n",
        "    print(f\"Loaded data from {DATA_PATH}\")\n",
        "\n",
        "    # Filter for Radiology reports and create a copy to avoid SettingWithCopyWarning\n",
        "    df = data[data['CATEGORY'] == 'Radiology'].copy()\n",
        "    print(f\"Filtered {len(df)} Radiology reports.\")\n",
        "\n",
        "    # --- Sampling ---\n",
        "    if len(df) > SAMPLE_SIZE:\n",
        "         full_df = df.sample(n=SAMPLE_SIZE, random_state=SEED).reset_index(drop=True)\n",
        "    else:\n",
        "         full_df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "    print(f\"Selected {len(full_df)} Radiology samples for processing.\")\n",
        "\n",
        "    # --- Text Cleaning and Initial Filtering ---\n",
        "    print(\"Cleaning text and applying initial word count filters...\")\n",
        "    full_df['TEXT'] = full_df['TEXT'].fillna(\"\").astype(str) # Ensure string type and handle NaNs\n",
        "    # Normalize whitespace (replace newlines/returns with spaces, then compress spaces)\n",
        "    full_df['TEXT'] = full_df['TEXT'].progress_apply(lambda x: ' '.join(x.replace('\\\\n', ' ').replace('\\\\r', ' ').strip().split()))\n",
        "\n",
        "    # Filter texts shorter than min_word_count\n",
        "    original_len = len(full_df)\n",
        "    full_df = full_df[full_df['TEXT'].apply(lambda x: len(x.split())) >= min_word_count].copy()\n",
        "    print(f\"Removed {original_len - len(full_df)} samples shorter than {min_word_count} words.\")\n",
        "\n",
        "    # Truncate texts longer than max_word_count\n",
        "    full_df['TEXT'] = full_df['TEXT'].progress_apply(lambda x: ' '.join(x.split()[:max_word_count]))\n",
        "    print(f\"Truncated texts longer than {max_word_count} words.\")\n",
        "\n",
        "\n",
        "    # --- Generate TF-IDF Target Summary ---\n",
        "    print(f\"Generating TF-IDF target summaries ('target_text') with ratio {tfidf_ratio}...\")\n",
        "    full_df['target_text'] = full_df['TEXT'].progress_apply(lambda x: create_extractive_summary_tfidf(x, ratio=tfidf_ratio))\n",
        "\n",
        "\n",
        "    # --- Add Section Tokens ---\n",
        "    print(\"Adding section tokens to original text ('section_aware_text')...\")\n",
        "    full_df['section_aware_text'] = full_df['TEXT'].progress_apply(add_section_tokens)\n",
        "\n",
        "\n",
        "    # --- Determine Length Control Token ---\n",
        "    print(f\"Determining length control tokens ('control_token') based on target summary word count (thresholds: short<={short_threshold}, medium<={medium_threshold})...\")\n",
        "    full_df['control_token'] = full_df['target_text'].apply(lambda x: get_length_control_token(x, short_threshold, medium_threshold))\n",
        "\n",
        "\n",
        "    # --- Create Final Input Text ---\n",
        "    print(\"Creating final input text ('input_text') by prepending control token...\")\n",
        "    # The final input text format is <LENGTH_TOKEN> <SECTION_AWARE_TEXT>\n",
        "    full_df['input_text'] = full_df['control_token'] + \" \" + full_df['section_aware_text']\n",
        "\n",
        "\n",
        "    # --- Final Cleanup: Remove samples with empty targets/inputs after processing ---\n",
        "    # This step is crucial if TF-IDF or section parsing resulted in empty strings for some samples\n",
        "    original_len = len(full_df)\n",
        "    full_df = full_df[full_df['target_text'].apply(lambda x: len(str(x).strip()) > 0)].copy() # Ensure string type before strip\n",
        "    full_df = full_df[full_df['input_text'].apply(lambda x: len(str(x).strip()) > 0)].copy()   # Ensure string type before strip\n",
        "    print(f\"Removed {original_len - len(full_df)} samples with empty targets/inputs after processing.\")\n",
        "    full_df = full_df.reset_index(drop=True) # Reset index after filtering\n",
        "\n",
        "\n",
        "    # --- Data Splitting ---\n",
        "    print(\"Splitting data into Train, Validation, and Test sets...\")\n",
        "    # Keep original TEXT column for clinical evaluation raw input\n",
        "    train_df, temp_df = train_test_split(full_df[['input_text', 'target_text', 'TEXT']],\n",
        "                                         test_size=0.3, random_state=SEED)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED)\n",
        "\n",
        "    # Reset indices for easier access later\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    val_df = val_df.reset_index(drop=True)\n",
        "    test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "    print(f\"Train set size: {len(train_df)}\")\n",
        "    print(f\"Validation set size: {len(val_df)}\")\n",
        "    print(f\"Test set size: {len(test_df)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Data file not found at {DATA_PATH}. Please check the path in the Configuration cell.\")\n",
        "    # Exit or handle gracefully\n",
        "    # exit()\n",
        "except KeyError as e:\n",
        "    print(f\"Error: Missing expected column in CSV: {e}. Ensure 'TEXT' and 'CATEGORY' columns exist in your data file.\")\n",
        "    # exit()\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during data loading/preprocessing: {e}\")\n",
        "    # exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nKjyUBpG9yMT"
      },
      "outputs": [],
      "source": [
        "# (Cell 6) Custom Dataset Class\n",
        "\n",
        "class MIMICDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for MIMIC-III Radiology Reports.\"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_input_length, max_target_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_target_length = max_target_length\n",
        "        # Check required columns in the dataframe\n",
        "        required_cols = ['input_text', 'target_text', 'TEXT'] # TEXT holds original for raw_input\n",
        "        if not all(col in dataframe.columns for col in required_cols):\n",
        "             raise ValueError(f\"Dataframe must contain columns: {required_cols}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Retrieves a single sample by index.\"\"\"\n",
        "        if idx >= len(self.dataframe): raise IndexError(\"Index out of bounds\")\n",
        "\n",
        "        # Get the texts for the current sample\n",
        "        input_text = str(self.dataframe.iloc[idx]['input_text'])   # Final input with control+section tokens\n",
        "        target_text = str(self.dataframe.iloc[idx]['target_text']) # TF-IDF summary (Target for loss)\n",
        "        raw_original_text = str(self.dataframe.iloc[idx]['TEXT'])  # Original report text (for clinical metrics)\n",
        "\n",
        "\n",
        "        # Tokenize the input text\n",
        "        input_encoding = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_input_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\" # Return PyTorch tensors\n",
        "        )\n",
        "\n",
        "        # Tokenize the target text. Use as_target_tokenizer() for correct handling of BOS/EOS/padding tokens for the decoder.\n",
        "        with self.tokenizer.as_target_tokenizer():\n",
        "            target_encoding = self.tokenizer(\n",
        "                target_text,\n",
        "                max_length=self.max_target_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\" # Return PyTorch tensors\n",
        "            )\n",
        "\n",
        "        labels = target_encoding['input_ids']\n",
        "        # Replace padding token id in labels with -100 so it's ignored in the loss calculation\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_encoding['input_ids'].flatten(), # Remove batch dimension\n",
        "            'attention_mask': input_encoding['attention_mask'].flatten(), # Remove batch dimension\n",
        "            'labels': labels.flatten(), # Remove batch dimension\n",
        "            'raw_input': raw_original_text, # Include original text for clinical evaluation\n",
        "            'raw_target': target_text      # Include TF-IDF target for standard evaluation\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OgXLCEO590IF"
      },
      "outputs": [],
      "source": [
        "# (Cell 7) Evaluation Metric Functions\n",
        "\n",
        "def calculate_metrics(references, hypotheses):\n",
        "\n",
        "    # Normalize texts before calculating metrics\n",
        "    references = [normalize_text(ref) for ref in references]\n",
        "    hypotheses = [normalize_text(hyp) for hyp in hypotheses]\n",
        "\n",
        "    rouge1_scores, rouge2_scores, rougeL_scores, bleu_scores = [], [], [], []\n",
        "\n",
        "    # Calculate ROUGE scores for each pair\n",
        "    for ref, hyp in zip(references, hypotheses):\n",
        "        # Skip empty references or hypotheses for ROUGE calculation\n",
        "        if not ref or not hyp:\n",
        "             # print(f\"Warning: Skipping empty reference or hypothesis for ROUGE. Ref: '{ref[:20]}...', Hyp: '{hyp[:20]}...'\")\n",
        "            continue\n",
        "        try:\n",
        "            # Calculate ROUGE scores for the current reference-hypothesis pair\n",
        "            scores = scorer.score(ref, hyp)\n",
        "            rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "            rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "            rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating ROUGE for pair: ref='{ref[:50]}...', hyp='{hyp[:50]}...'. Error: {e}\")\n",
        "\n",
        "\n",
        "    # Calculate BLEU scores for each pair\n",
        "    for ref, hyp in zip(references, hypotheses):\n",
        "         # Skip empty references or hypotheses for BLEU calculation\n",
        "         if not ref or not hyp:\n",
        "              # print(f\"Warning: Skipping empty reference or hypothesis for BLEU. Ref: '{ref[:20]}...', Hyp: '{hyp[:20]}...'\")\n",
        "             continue\n",
        "         try:\n",
        "            # Tokenize sentences for BLEU calculation\n",
        "            ref_tokens = nltk.word_tokenize(ref)\n",
        "            hyp_tokens = nltk.word_tokenize(hyp)\n",
        "            # Skip if tokenization results in empty lists\n",
        "            if not ref_tokens or not hyp_tokens:\n",
        "                 # print(f\"Warning: Skipping BLEU due to empty token lists. Ref: '{ref[:20]}...', Hyp: '{hyp[:20]}...'\")\n",
        "                 continue\n",
        "            # Calculate BLEU score using sentence_bleu with smoothing\n",
        "            # sentence_bleu expects a list of reference sentences (even if only one)\n",
        "            bleu_score = sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoother)\n",
        "            bleu_scores.append(bleu_score)\n",
        "         except Exception as e:\n",
        "             print(f\"Error calculating BLEU for pair: ref='{ref[:50]}...', hyp='{hyp[:50]}...'. Error: {e}\")\n",
        "\n",
        "\n",
        "    # Calculate average scores, handling cases with no valid scores\n",
        "    avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores) if rouge1_scores else 0.0\n",
        "    avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores) if rouge2_scores else 0.0\n",
        "    avg_rougeL = sum(rougeL_scores) / len(rougeL_scores) if rougeL_scores else 0.0\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0.0\n",
        "\n",
        "    return {\n",
        "        'rouge-1': avg_rouge1,\n",
        "        'rouge-2': avg_rouge2,\n",
        "        'rouge-l': avg_rougeL,\n",
        "        'bleu': avg_bleu\n",
        "    }\n",
        "\n",
        "\n",
        "# Clinical Metrics (Entity Overlap F1)\n",
        "# scispaCy model (nlp_sci) and TARGET_ENTITY_TYPES are initialized in Cell 1\n",
        "\n",
        "def calculate_clinical_metrics(references_raw, hypotheses, target_entity_types=TARGET_ENTITY_TYPES):\n",
        "\n",
        "    # Check if scispaCy model is loaded and target entity types are defined\n",
        "    if not SCISPACY_LOADED or not target_entity_types:\n",
        "        if not SCISPACY_LOADED:\n",
        "             print(\"Warning: scispaCy model not loaded. Skipping clinical metrics calculation.\")\n",
        "        elif not target_entity_types:\n",
        "             print(\"Warning: No target entity types defined for clinical metrics. Skipping calculation.\")\n",
        "        return {'entity_recall': 0.0, 'entity_precision': 0.0, 'entity_f1': 0.0}\n",
        "\n",
        "    all_recalls, all_precisions, all_f1s = [], [], []\n",
        "    processed_pairs_count = 0 # Counter for pairs successfully processed by scispaCy\n",
        "\n",
        "    print(f\"Calculating clinical metrics for {len(references_raw)} pairs using entity types: {target_entity_types}...\")\n",
        "    # Use tqdm for a progress bar during this potentially slow process\n",
        "    for ref_text, hyp_text in tqdm(zip(references_raw, hypotheses), total=len(references_raw), desc=\"Clinical Metrics\"):\n",
        "        # Ensure texts are strings and not empty or just whitespace\n",
        "        ref_text = str(ref_text).strip()\n",
        "        hyp_text = str(hyp_text).strip()\n",
        "\n",
        "        if not ref_text or not hyp_text:\n",
        "            # print(f\"Skipping pair due to empty reference or hypothesis string after stripping.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Process the original raw text (reference for entities) with scispaCy\n",
        "            doc_ref = nlp_sci(ref_text)\n",
        "            # Extract entities of target types, convert lemma to lower case for comparison\n",
        "            ref_entities = {ent.lemma_.lower() for ent in doc_ref.ents if ent.label_ in target_entity_types}\n",
        "\n",
        "            # Process the generated summary (hypothesis) with scispaCy\n",
        "            doc_hyp = nlp_sci(hyp_text)\n",
        "            hyp_entities = {ent.lemma_.lower() for ent in doc_hyp.ents if ent.label_ in target_entity_types}\n",
        "\n",
        "            # Calculate the number of entities common to both original text and generated summary\n",
        "            common_entities_count = len(ref_entities.intersection(hyp_entities))\n",
        "\n",
        "            # Calculate Recall, Precision, and F1 score for this pair\n",
        "            # Recall: Proportion of entities in the reference (original text) that are found in the hypothesis (generated summary)\n",
        "            recall = common_entities_count / len(ref_entities) if len(ref_entities) > 0 else 0.0\n",
        "            # Precision: Proportion of entities in the hypothesis (generated summary) that are found in the reference (original text)\n",
        "            precision = common_entities_count / len(hyp_entities) if len(hyp_entities) > 0 else 0.0\n",
        "            # F1 Score: Harmonic mean of Precision and Recall\n",
        "            f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "            # Append scores for this pair to the lists\n",
        "            all_recalls.append(recall)\n",
        "            all_precisions.append(precision)\n",
        "            all_f1s.append(f1)\n",
        "            processed_pairs_count += 1 # Increment counter for successfully processed pairs\n",
        "\n",
        "        except Exception as e:\n",
        "            # Catch any errors during scispaCy processing for a specific pair\n",
        "            print(f\"\\nError processing pair with scispaCy (Index {processed_pairs_count}) - ref='{ref_text[:50]}...', hyp='{hyp_text[:50]}...'. Error: {e}\\n\")\n",
        "            # Decide how to handle errors: skipping the pair or appending zeros. Skipping is chosen here.\n",
        "            continue\n",
        "\n",
        "    print(f\"Finished processing {processed_pairs_count} pairs for clinical metrics.\")\n",
        "\n",
        "    # Calculate average scores across all processed pairs, handling case with no processed pairs\n",
        "    avg_recall = sum(all_recalls) / len(all_recalls) if all_recalls else 0.0\n",
        "    avg_precision = sum(all_precisions) / len(all_precisions) if all_precisions else 0.0\n",
        "    avg_f1 = sum(all_f1s) / len(all_f1s) if all_f1s else 0.0\n",
        "\n",
        "    return {\n",
        "        'entity_recall': avg_recall,\n",
        "        'entity_precision': avg_precision,\n",
        "        'entity_f1': avg_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JRbJK56O933r"
      },
      "outputs": [],
      "source": [
        "# (Cell 8) Training Strategy Functions\n",
        "\n",
        "# Curriculum Learning Function\n",
        "def get_curriculum_dataset(current_epoch, train_df, tokenizer,\n",
        "                           initial_size=curriculum_learning_schedule[\"initial_size\"],\n",
        "                           increment=curriculum_learning_schedule[\"increment\"],\n",
        "                           increment_every=curriculum_learning_schedule[\"increment_every_epochs\"]):\n",
        "\n",
        "    # Determine the current phase based on the epoch number\n",
        "    epoch_phase = current_epoch // increment_every\n",
        "\n",
        "    # Calculate the target sample size for the current phase\n",
        "    sample_size = initial_size + epoch_phase * increment\n",
        "\n",
        "    # Ensure the calculated sample size does not exceed the total number of available training samples\n",
        "    sample_size = min(sample_size, len(train_df))\n",
        "\n",
        "    print(f\"Epoch {current_epoch+1}: Using {sample_size} training samples (Curriculum Learning).\")\n",
        "\n",
        "    # Create a subset of the training dataframe using the calculated sample size\n",
        "    # .iloc[:sample_size] takes the first 'sample_size' rows\n",
        "    current_train_df = train_df.iloc[:sample_size]\n",
        "\n",
        "    # Create and return a MIMICDataset instance for the selected subset\n",
        "    return MIMICDataset(current_train_df, tokenizer, max_input_length=MAX_INPUT_LENGTH, max_target_length=MAX_TARGET_LENGTH)\n",
        "\n",
        "\n",
        "# Progressive Unfreezing Function\n",
        "def unfreeze_layers(model, epoch, optimizer, initial_lr, unfreezing_schedule=progressive_unfreezing_schedule):\n",
        "    \"\"\"\n",
        "    Unfreezes more layers of the model at specified epochs and re-initializes optimizer if needed.\n",
        "\n",
        "    Args:\n",
        "        model: The model instance.\n",
        "        epoch (int): The current epoch number (starting from 0).\n",
        "        optimizer: The current optimizer instance.\n",
        "        initial_lr: The initial learning rate.\n",
        "        unfreezing_schedule (dict): Dictionary mapping epoch numbers (0-indexed) to unfreezing actions.\n",
        "\n",
        "    Returns:\n",
        "        The potentially re-initialized optimizer.\n",
        "    \"\"\"\n",
        "    optimizer_reset_needed = False # Flag to indicate if the optimizer needs to be reset\n",
        "\n",
        "    # Check if the current epoch is in the unfreezing schedule\n",
        "    if epoch in unfreezing_schedule:\n",
        "        action = unfreezing_schedule[epoch]\n",
        "        print(f\"\\n--- Epoch {epoch+1}: Applying Progressive Unfreezing action: '{action}' ---\")\n",
        "\n",
        "        if action == \"unfreeze_all_decoder\":\n",
        "            # Unfreeze all parameters in the decoder\n",
        "            for name, param in model.model.decoder.named_parameters():\n",
        "                 if not param.requires_grad: # Only change if not already trainable\n",
        "                      param.requires_grad = True\n",
        "                      optimizer_reset_needed = True\n",
        "            print(\"All decoder layers are now trainable.\")\n",
        "\n",
        "        elif action == \"unfreeze_half_encoder\":\n",
        "            # Unfreeze the top half of the encoder layers\n",
        "            encoder_layers = model.model.encoder.layers\n",
        "            num_encoder_layers = len(encoder_layers)\n",
        "            num_layers_to_unfreeze = num_encoder_layers // 2 # Unfreeze the top half\n",
        "\n",
        "            print(f\"Unfreezing the top {num_layers_to_unfreeze} out of {num_encoder_layers} encoder layers.\")\n",
        "            # Iterate through encoder layers and unfreeze the top ones\n",
        "            for i, layer in enumerate(encoder_layers):\n",
        "                 # Unfreeze layers from num_layers_to_unfreeze onwards (0-indexed)\n",
        "                 if i >= (num_encoder_layers - num_layers_to_unfreeze):\n",
        "                      # Check if any parameter in the layer is not already trainable\n",
        "                      if not any(p.requires_grad for p in layer.parameters()):\n",
        "                           print(f\"Unfreezing encoder layer {i} (Index {i}/{num_encoder_layers-1})\")\n",
        "                           for param in layer.parameters():\n",
        "                                param.requires_grad = True\n",
        "                           optimizer_reset_needed = True\n",
        "            print(\"Specified encoder layers are now trainable.\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Warning: Unknown unfreezing action '{action}' specified in schedule for epoch {epoch+1}.\")\n",
        "\n",
        "\n",
        "    # This ensures the new parameters are added to the optimizer's state.\n",
        "    if optimizer_reset_needed:\n",
        "         print(\"Re-initializing optimizer due to layer unfreezing...\")\n",
        "         # Create a new optimizer instance, including all currently trainable parameters\n",
        "         trainable_model_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "         optimizer = AdamW(trainable_model_params, lr=initial_lr) # Use the initial learning rate\n",
        "         print(\"Optimizer re-initialized with current trainable parameters.\")\n",
        "\n",
        "    # Print the ratio of trainable parameters after applying any unfreezing\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Current trainable parameters: {trainable_params:,} / {total_params:,} ({100 * trainable_params / total_params:.2f}%)\\\\n\")\n",
        "\n",
        "    return optimizer # Return the (potentially new) optimizer instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DfqYOovn97Kr"
      },
      "outputs": [],
      "source": [
        "# (Cell 9) Checkpointing and Metrics Saving Functions\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, metrics, checkpoint_path):\n",
        "\n",
        "    print(f\"Saving checkpoint for epoch {epoch+1} to {checkpoint_path}...\")\n",
        "    try:\n",
        "        checkpoint = {\n",
        "            'epoch': epoch, # Save the 0-indexed epoch number\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'metrics': metrics # Save the latest validation metrics dictionary\n",
        "        }\n",
        "        # Ensure directory exists before saving\n",
        "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        print(\"Checkpoint saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving checkpoint to {checkpoint_path}: {e}\")\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer, device):\n",
        "\n",
        "    # Check if the checkpoint file exists\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
        "        try:\n",
        "            # Load the checkpoint dictionary, mapping to the specified device\n",
        "            checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "            # Load the model state dictionary\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(\"Model state loaded.\")\n",
        "\n",
        "            # Load the optimizer state dictionary only if an optimizer is provided\n",
        "            if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
        "                 try:\n",
        "                      # Load optimizer state - handles parameters added by unfreezing if they match\n",
        "                      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "                      print(\"Optimizer state loaded.\")\n",
        "                 except ValueError as e:\n",
        "                      # This can happen if the set of trainable parameters changed significantly\n",
        "                      print(f\"Warning: Could not load optimizer state, possibly due to parameter changes: {e}\")\n",
        "                      print(\"Optimizer state will be re-initialized for trainable parameters.\")\n",
        "                      # Re-initialize optimizer with current trainable parameters if loading failed\n",
        "                      if optimizer is not None: # Double check optimizer is not None\n",
        "                           trainable_model_params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "                           # Use the LR from the loaded checkpoint if available, otherwise fallback to initial\n",
        "                           loaded_lr = next(iter(checkpoint['optimizer_state_dict']['param_groups']))['lr'] if 'optimizer_state_dict' in checkpoint and checkpoint['optimizer_state_dict']['param_groups'] else INITIAL_LR\n",
        "                           optimizer = AdamW(trainable_model_params, lr=loaded_lr)\n",
        "                           print(\"Optimizer re-initialized with current trainable parameters.\")\n",
        "\n",
        "\n",
        "            # Determine the epoch to start from. Add 1 because the saved epoch is the one that just finished.\n",
        "            # Use .get with a default for robustness against older checkpoint formats\n",
        "            start_epoch = checkpoint.get('epoch', -1) + 1\n",
        "            # Load the metrics dictionary saved with this checkpoint\n",
        "            loaded_metrics = checkpoint.get('metrics', {})\n",
        "\n",
        "            print(f\"Checkpoint loaded successfully. Resuming training from epoch {start_epoch}\")\n",
        "            return model, optimizer, start_epoch, loaded_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle errors during loading\n",
        "            print(f\"Error loading checkpoint from {checkpoint_path}: {e}\")\n",
        "            print(\"Starting training from scratch (Epoch 0).\")\n",
        "            # Return initial state if loading fails\n",
        "            return model, optimizer, 0, {} # Start from epoch 0, return empty metrics\n",
        "\n",
        "    else:\n",
        "        # If checkpoint file does not exist\n",
        "        print(f\"Checkpoint file not found at {checkpoint_path}. Starting training from scratch (Epoch 0).\")\n",
        "        return model, optimizer, 0, {} # Start from epoch 0, return empty metrics\n",
        "\n",
        "\n",
        "def save_metrics(metrics_dict, file_path):\n",
        "\n",
        "    print(f\"Saving metrics history to {file_path}...\")\n",
        "    try:\n",
        "        # Ensure directory exists\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            # Convert any numpy types (like numpy.float64) to native Python types\n",
        "            # for JSON serialization. This is done for lists of numbers.\n",
        "            serializable_metrics = {}\n",
        "            for key, value in metrics_dict.items():\n",
        "                if isinstance(value, list) and value and isinstance(value[0], (np.generic, float, int)):\n",
        "                     # Convert each item in the list if it's a numpy generic type\n",
        "                     serializable_metrics[key] = [item.item() if isinstance(item, np.generic) else item for item in value]\n",
        "                else:\n",
        "                     # For non-list values or lists of other types, just use the value directly\n",
        "                     serializable_metrics[key] = value\n",
        "\n",
        "            # Dump the serializable dictionary to the JSON file with indentation\n",
        "            json.dump(serializable_metrics, f, ensure_ascii=False, indent=4)\n",
        "        print(\"Metrics history saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving metrics history to {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649,
          "referenced_widgets": [
            "e304d861011148349ed242d3aeb5c7e8",
            "bd538c3d760e428a8f8eaf3f8b9e58b2",
            "951a3eebf7524f6fa0f8b5730fa4f96c",
            "e502a214f02a487eb6e207b48232bd69",
            "c41637a5a6d9476bb754de3b270e9d4d",
            "162d0860abc147c18eba0a607abecb9d",
            "fd32603814684cf4bec95d8c79d60a73",
            "cfcfcad16b94435fac2f14c2e9a5aa41",
            "0307de9f65ec457bb1664f3a7bcd6349",
            "7262a47c43ac48a0adb64518648defa6",
            "992c35ab8fb4453ab948c0c93c5b1660",
            "140a79077a6c450ba6ee27c3ca3691fb",
            "037c1fcafeba42eda09e5eb5c9d533bf",
            "13930fbacbb8497d94d4f18450b893b6",
            "ae879a076cd24c6a96ebc14f2bba5a26",
            "0abc418740554de5b6d3842d2f34c8a3",
            "ed0d5f0f947b471787cfbf9d844f216f",
            "36c329c363c54a8db7825cfde836ced7",
            "c3e8aff5f32c4b53860844df7f4b089d",
            "7a9b5a315ccd417f95101515219ac6ed",
            "e63546422a4945638152f008448018c6",
            "657fb591fefe4893a65efcaae6b5ce9c",
            "88a571bb87334ad8b3136fe8c8136ea3",
            "c9e444903dc7479ca7aad336802f78f9",
            "e598ad76ad704259a3e7c825a999ebd3",
            "5df8dfa403d942c5a86c343b8b03c7cf",
            "9e61ee7bcff3499493bd3cf237822675",
            "af799bb162104b7db88e7f58a2e6bd59",
            "29316412a6264aae919230d79b514671",
            "1106ab13a0604ac7b7855ff0fe1e9c81",
            "e624939b05e64dbc815df3237f076b67",
            "869316973b24472a899cdae86a93cc44",
            "f01174c687b14b3fa79fe6af271b5e85",
            "57d2a6af2e414e65ac88ba874c093bd8",
            "acbf1a1a34ea45fcad9dce3425a7d3a2",
            "de9efd74d7014cfa88f3b41b985c8fb3",
            "d7891d15ccef4eda8d570c8bb928ec2d",
            "a7c233a9ba3446f2a0720c69ac97a9c7",
            "10e85c85ef0b41189a55b38773cca882",
            "8f911fcffda04be19eaf2a7c58eb1008",
            "09247310e211474a83e15b9f30edc803",
            "695bb75f52d64db68c5f33eb4e881626",
            "1043df36cbc44582af7f845a1d733733",
            "8398eb08289f4584a6120ced3eb0c31d",
            "cec478c936c9467abe9ad09d882c0def",
            "a3e79fed0e4b46e982b2bf417a123def",
            "206d8e23785d42c8b0c0bafaa8f76a59",
            "e2b58fa6ed544418bfed25d349c44348",
            "6f53e6be731a4362a00f38c5e1cd09ab",
            "ad431124930a4cd7928058db5eebfb36",
            "4df84814bc8f4efab75ef61885c40846",
            "8b275d42722d43cd8de40666529bde27",
            "91fd70b7299d485e9c43788fc76d078c",
            "1878a86011f54ae4b390976bc4a5b553",
            "0dfc95974a2343cdb7a6413a61ef3029",
            "38d671007f4944e7ad6d4b75f2c6a540",
            "ad9a7b0fd1bb4a2881a26f9c6209d387",
            "9ac15ca3f31e4c72b1facb3d9f61d485",
            "2a30e8aeabf84e9090d455194bedef2a",
            "2a05f58e51c34829af9bb83e67981692",
            "66f8251e74464f6eb9afa680edefbec2",
            "32c1deafe1d8449aa5811a4e795c9a2c",
            "45a3001c0c7d4b41a43f3ab5e2333ccf",
            "a8a55ebfbe7141fb9b12c61a0f2e9b5f",
            "dfb5d2c379114335974f1cf0fbfc1a76",
            "ba8b6220ad7344fe93711d1d0e91c576"
          ]
        },
        "id": "SRMSbNdh99KF",
        "outputId": "e954484e-6b15-4b53-db7e-259eaa6093ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model and tokenizer: GanjinZero/biobart-v2-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e304d861011148349ed242d3aeb5c7e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "140a79077a6c450ba6ee27c3ca3691fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/892k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88a571bb87334ad8b3136fe8c8136ea3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57d2a6af2e414e65ac88ba874c093bd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cec478c936c9467abe9ad09d882c0def"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/666M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38d671007f4944e7ad6d4b75f2c6a540"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding 9 new special tokens to tokenizer vocabulary: ['<SUM_SHORT>', '<SUM_LONG>', '[TECHNIQUE_SEP]', '<SUM_MEDIUM>', '[REASON_SEP]', '[FINDINGS_SEP]', '[IMPRESSION_SEP]', '[CONCLUSION_SEP]', '[INDICATION_SEP]']\n",
            "Number of tokens added: 9\n",
            "Resizing model token embeddings from 85401 to 85410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model vocabulary size after resizing: 85410\n",
            "Tokenizer with special tokens saved to /content/drive/MyDrive/BioBart_TFIDF_Structured/tokenizer\n",
            "Applying initial layer freezing strategy...\n",
            "Unfroze shared embeddings.\n",
            "Unfroze language model head (lm_head).\n",
            "Unfreezing the last 4 decoder layers.\n",
            "Unfreezing decoder layer 2 (Index 2/5)\n",
            "Unfreezing decoder layer 3 (Index 3/5)\n",
            "Unfreezing decoder layer 4 (Index 4/5)\n",
            "Unfreezing decoder layer 5 (Index 5/5)\n",
            "\n",
            "Trainable parameters after initial freezing: 103,401,984 / 166,411,776 (62.14%)\\n\n"
          ]
        }
      ],
      "source": [
        "# (Cell 10) Model and Tokenizer Setup\n",
        "\n",
        "print(f\"Loading base model and tokenizer: {model_name}\")\n",
        "try:\n",
        "    # Load base tokenizer and model from Hugging Face Hub\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "    # Add ALL new special tokens defined in Configuration cell\n",
        "    print(f\"Adding {len(ALL_NEW_SPECIAL_TOKENS)} new special tokens to tokenizer vocabulary: {ALL_NEW_SPECIAL_TOKENS}\")\n",
        "    special_tokens_dict = {'additional_special_tokens': ALL_NEW_SPECIAL_TOKENS}\n",
        "    num_added = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    print(f\"Number of tokens added: {num_added}\")\n",
        "\n",
        "    # Resize model embeddings to match the new tokenizer size.\n",
        "    # This adds new embedding vectors for the newly added tokens, initialized randomly.\n",
        "    print(f\"Resizing model token embeddings from {model.config.vocab_size} to {len(tokenizer)}\")\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    print(f\"Model vocabulary size after resizing: {model.get_input_embeddings().weight.shape[0]}\")\n",
        "\n",
        "    # Save the modified tokenizer configuration (including new tokens)\n",
        "    tokenizer.save_pretrained(TOKENIZER_PATH)\n",
        "    print(f\"Tokenizer with special tokens saved to {TOKENIZER_PATH}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model/tokenizer or adding tokens: {e}\")\n",
        "    # Exit gracefully if model/tokenizer setup fails\n",
        "    # exit()\n",
        "\n",
        "\n",
        "# --- Initial Layer Freezing Strategy ---\n",
        "# Freeze most layers initially and only train specific parts.\n",
        "print(\"Applying initial layer freezing strategy...\")\n",
        "\n",
        "# Freeze all model parameters by default\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze shared embeddings\n",
        "if model.model.shared is not None:\n",
        "     for param in model.model.shared.parameters():\n",
        "          param.requires_grad = True\n",
        "     print(\"Unfroze shared embeddings.\")\n",
        "\n",
        "# Unfreeze the language model head\n",
        "for param in model.lm_head.parameters():\n",
        "    param.requires_grad = True\n",
        "print(\"Unfroze language model head (lm_head).\")\n",
        "\n",
        "# Unfreeze the last N decoder layers (N is num_decoder_layers_to_unfreeze_initial)\n",
        "decoder_layers = model.model.decoder.layers\n",
        "num_decoder_layers = len(decoder_layers)\n",
        "num_layers_to_unfreeze = min(num_decoder_layers_to_unfreeze_initial, num_decoder_layers) # Ensure N is not more than total layers\n",
        "\n",
        "print(f\"Unfreezing the last {num_layers_to_unfreeze} decoder layers.\")\n",
        "for i in range(num_decoder_layers - num_layers_to_unfreeze, num_decoder_layers):\n",
        "    print(f\"Unfreezing decoder layer {i} (Index {i}/{num_decoder_layers-1})\")\n",
        "    for param in decoder_layers[i].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Print the ratio of trainable parameters after initial freezing\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nTrainable parameters after initial freezing: {trainable_params:,} / {total_params:,} ({100 * trainable_params / total_params:.2f}%)\\\\n\")\n",
        "\n",
        "# Clean up memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4mc025e9_Zr",
        "outputId": "76a18704-8679-4afe-9b60-3acca67a8440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating datasets and dataloaders...\n",
            "Validation Dataloader created with 1965 batches.\n",
            "Test Dataloader created with 1965 batches.\n",
            "Using device: cuda\n",
            "Model moved to device.\n",
            "Optimizer initialized with learning rate: 2e-05\n",
            "Initialized GradScaler for Automatic Mixed Precision (AMP).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c632af47c4ef>:53: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# (Cell 11) Create Datasets and DataLoaders\n",
        "\n",
        "print(\"Creating datasets and dataloaders...\")\n",
        "\n",
        "try:\n",
        "    # Create Dataset instances for validation and test sets\n",
        "    # Training dataset is created dynamically in the training loop for Curriculum Learning\n",
        "    val_dataset = MIMICDataset(val_df, tokenizer, max_input_length=MAX_INPUT_LENGTH, max_target_length=MAX_TARGET_LENGTH)\n",
        "    test_dataset = MIMICDataset(test_df, tokenizer, max_input_length=MAX_INPUT_LENGTH, max_target_length=MAX_TARGET_LENGTH)\n",
        "\n",
        "    # Create DataLoader instances for validation and test sets\n",
        "    # num_workers > 0 can speed up data loading, pin_memory=True can speed up CPU-to-GPU transfer\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(f\"Validation Dataloader created with {len(val_dataloader)} batches.\")\n",
        "    print(f\"Test Dataloader created with {len(test_dataloader)} batches.\")\n",
        "\n",
        "except ValueError as e:\n",
        "     print(f\"Error creating dataset: {e}\")\n",
        "     # exit()\n",
        "except Exception as e:\n",
        "     print(f\"An unexpected error occurred during dataset/dataloader creation: {e}\")\n",
        "     # exit()\n",
        "\n",
        "# --- Device Setup ---\n",
        "# Determine the device to use (GPU if available, otherwise CPU)\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache() # Clear GPU cache before moving model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move the model to the selected device\n",
        "try:\n",
        "    model.to(device)\n",
        "    print(\"Model moved to device.\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"Error moving model to {device}: {e}. Trying CPU.\")\n",
        "    device = torch.device('cpu')\n",
        "    model.to(device)\n",
        "    print(\"Model moved to CPU.\")\n",
        "\n",
        "\n",
        "# --- Optimizer and Scaler Setup ---\n",
        "# Initialize the optimizer with only the trainable parameters\n",
        "# Using AdamW, a common choice for transformer fine-tuning\n",
        "# The set of trainable parameters might change during progressive unfreezing\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=INITIAL_LR)\n",
        "print(f\"Optimizer initialized with learning rate: {INITIAL_LR}\")\n",
        "\n",
        "# Initialize GradScaler for Mixed Precision Training (AMP)\n",
        "# This helps speed up training and reduce memory usage on compatible GPUs\n",
        "scaler = GradScaler()\n",
        "print(\"Initialized GradScaler for Automatic Mixed Precision (AMP).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ0GXLMR-QBL",
        "outputId": "e78531f7-c4e4-4212-f4b1-398f31002e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training process...\n",
            "--- Best model not found, loading latest model from /content/drive/MyDrive/BioBart_TFIDF_Structured/latest_model.pt to resume training ---\n",
            "Loading checkpoint from /content/drive/MyDrive/BioBart_TFIDF_Structured/latest_model.pt...\n",
            "Model state loaded.\n",
            "Optimizer state loaded.\n",
            "Checkpoint loaded successfully. Resuming training from epoch 15\n",
            "Loaded latest model (Epoch 15)\n",
            "Resuming training from epoch 15\n",
            "Attempting to load previous metrics history from /content/drive/MyDrive/BioBart_TFIDF_Structured/training_metrics.json\n",
            "Loading history for 14 previous epochs.\n",
            "Metrics history loaded successfully and aligned with checkpoint.\n",
            "\n",
            "===== Training Completed =====\n",
            "Total training duration (successful epochs): 2541.46 minutes.\n"
          ]
        }
      ],
      "source": [
        "# (Cell 12) Training Loop\n",
        "\n",
        "print(\"\\nStarting training process...\")\n",
        "\n",
        "# Initialize variables for tracking metrics and best model\n",
        "best_val_metric = 0.0 # Initialize best validation metric (tracking ROUGE-L)\n",
        "best_model_epoch = -1 # Track the epoch number where the best model was found\n",
        "\n",
        "# --- Checkpoint Loading and History Loading ---\n",
        "\n",
        "# Define the metrics keys that are expected in the history file\n",
        "# This list is comprehensive and includes all metrics we track\n",
        "expected_keys = {\n",
        "    'train_loss': [], 'val_loss': [],\n",
        "    'rouge-1': [], 'rouge-2': [], 'rouge-l': [], 'bleu': [],\n",
        "    'entity_recall': [], 'entity_precision': [], 'entity_f1': [],\n",
        "    'sample_sizes': [], # Size of the training dataset subset used in each epoch\n",
        "    'epoch_runtime_seconds': [] # Duration of each epoch in seconds\n",
        "}\n",
        "\n",
        "# Initialize the dictionary to store the training history for all metrics\n",
        "# This dictionary will be populated from a saved file or start fresh\n",
        "all_metrics = {key: [] for key in expected_keys}\n",
        "\n",
        "# Paths for checkpoints\n",
        "latest_model_path = os.path.join(DRIVE_PATH, \"latest_model.pt\")\n",
        "best_model_path = os.path.join(DRIVE_PATH, \"best_model.pt\")\n",
        "\n",
        "# Determine the starting epoch and load model/optimizer state from checkpoint\n",
        "start_epoch = 0 # Default start epoch\n",
        "loaded_metrics_from_checkpoint = {} # Metrics dictionary saved within the checkpoint\n",
        "\n",
        "# If the best model checkpoint is not found, try loading the latest model checkpoint\n",
        "if os.path.exists(latest_model_path):\n",
        "    print(f\"--- Best model not found, loading latest model from {latest_model_path} to resume training ---\")\n",
        "    # load_checkpoint updates model, optimizer, start_epoch, and returns metrics saved with it\n",
        "    model, optimizer, start_epoch, loaded_metrics_from_checkpoint = load_checkpoint(latest_model_path, model, optimizer, device)\n",
        "    # Update best_val_metric based on the latest model's metrics (if available)\n",
        "    best_val_metric = loaded_metrics_from_checkpoint.get('rouge-l', 0.0)\n",
        "    # Get the epoch the latest model was trained at, default to start_epoch - 1\n",
        "    best_model_epoch = loaded_metrics_from_checkpoint.get('epoch', start_epoch - 1)\n",
        "    print(f\"Loaded latest model (Epoch {start_epoch})\") # Note: start_epoch is the *next* epoch number\n",
        "    print(f\"Resuming training from epoch {start_epoch}\")\n",
        "\n",
        "# Prioritize loading the best model checkpoint if it exists\n",
        "elif os.path.exists(best_model_path):\n",
        "    print(f\"--- Loading best model from {best_model_path} to resume training ---\")\n",
        "    # load_checkpoint updates model, optimizer, start_epoch, and returns metrics saved with it\n",
        "    model, optimizer, start_epoch, loaded_metrics_from_checkpoint = load_checkpoint(best_model_path, model, optimizer, device)\n",
        "    # Update best_val_metric and best_model_epoch based on the loaded best model's metrics\n",
        "    best_val_metric = loaded_metrics_from_checkpoint.get('rouge-l', 0.0)\n",
        "    # Get the epoch the best model was trained at, default to start_epoch - 1 if not found\n",
        "    best_model_epoch = loaded_metrics_from_checkpoint.get('epoch', start_epoch - 1)\n",
        "    print(f\"Loaded best model (Epoch {best_model_epoch + 1}) with ROUGE-L: {best_val_metric:.4f}\")\n",
        "    print(f\"Resuming training from epoch {start_epoch}\")\n",
        "\n",
        "# If no checkpoint is found, training starts from scratch (Epoch 0)\n",
        "else:\n",
        "    print(\"--- No checkpoint found, starting training from scratch (Epoch 0) ---\")\n",
        "    start_epoch = 0 # Explicitly set start_epoch to 0\n",
        "\n",
        "\n",
        "# --- Load Metrics History from File ---\n",
        "# Load the full training history (metrics for all previous epochs) from the JSON file\n",
        "# This is done *after* determining start_epoch from checkpoint\n",
        "METRICS_FILE = os.path.join(DRIVE_PATH, \"training_metrics.json\") # Ensure path is defined\n",
        "\n",
        "if os.path.exists(METRICS_FILE):\n",
        "    print(f\"Attempting to load previous metrics history from {METRICS_FILE}\")\n",
        "    try:\n",
        "        with open(METRICS_FILE, 'r', encoding='utf-8') as f:\n",
        "            loaded_metrics_hist = json.load(f)\n",
        "\n",
        "        # Validate the structure and load history up to the start_epoch\n",
        "        if isinstance(loaded_metrics_hist, dict):\n",
        "            # Create a temporary dictionary with the expected keys and empty lists\n",
        "            temp_metrics_for_load = {key: [] for key in expected_keys}\n",
        "            valid_load_successful = True # Flag to track if loading was entirely successful\n",
        "\n",
        "            # Determine the length of history available in the file based on the first expected key\n",
        "            first_key = list(expected_keys.keys())[0]\n",
        "            if first_key in loaded_metrics_hist and isinstance(loaded_metrics_hist[first_key], list):\n",
        "                 file_history_len = len(loaded_metrics_hist[first_key])\n",
        "            else:\n",
        "                 # If the first key is missing or not a list, the file structure is likely invalid\n",
        "                 file_history_len = 0\n",
        "                 valid_load_successful = False\n",
        "                 print(f\"Warning: Metrics file {METRICS_FILE} has unexpected format or is empty.\")\n",
        "\n",
        "\n",
        "            if valid_load_successful:\n",
        "                # Calculate the actual number of epochs to load history for.\n",
        "                # This is the minimum of the determined start_epoch and the history length in the file.\n",
        "                effective_history_len_to_load = min(start_epoch, file_history_len)\n",
        "\n",
        "                if effective_history_len_to_load > 0:\n",
        "                    print(f\"Loading history for {effective_history_len_to_load} previous epochs.\")\n",
        "                    # Load data for each expected key up to the effective history length\n",
        "                    for key in expected_keys:\n",
        "                        if key in loaded_metrics_hist and isinstance(loaded_metrics_hist[key], list) and len(loaded_metrics_hist[key]) >= effective_history_len_to_load:\n",
        "                             # Slice the list to get only the data up to start_epoch (0-indexed)\n",
        "                             temp_metrics_for_load[key] = loaded_metrics_hist[key][:effective_history_len_to_load]\n",
        "                        else:\n",
        "                             # If a key is missing in the file or its list is shorter than needed,\n",
        "                             # print a warning and keep the corresponding list empty in temp_metrics_for_load.\n",
        "                             print(f\"Warning: Data for key '{key}' is missing or incomplete in metrics file for loading up to epoch {start_epoch}. History for this key might be reset.\")\n",
        "                             valid_load_successful = False # Mark load as not fully successful for all keys\n",
        "                             temp_metrics_for_load[key] = [] # Ensure list is empty if load failed for this key\n",
        "\n",
        "                    if valid_load_successful: # If history for all expected keys was loaded correctly\n",
        "                         all_metrics = temp_metrics_for_load # Replace the initial empty all_metrics with loaded history\n",
        "                         print(\"Metrics history loaded successfully and aligned with checkpoint.\")\n",
        "                    else:\n",
        "                         print(\"Issues found during metrics history loading. Starting history fresh to avoid corruption.\")\n",
        "                         # If loading issues occurred, reset all_metrics to empty lists\n",
        "                         all_metrics = {key: [] for key in expected_keys}\n",
        "\n",
        "                # Handle cases where the file history length is greater than start_epoch\n",
        "                # This indicates a potential inconsistency between checkpoint and metrics file\n",
        "                elif file_history_len > start_epoch:\n",
        "                     print(f\"Warning: Metrics file contains data for {file_history_len} epochs, but resuming from epoch {start_epoch}. This suggests inconsistency. Starting history fresh.\")\n",
        "                     all_metrics = {key: [] for key in expected_keys} # Start fresh due to inconsistency\n",
        "\n",
        "                else: # file_history_len <= start_epoch and effective_history_len_to_load == 0\n",
        "                    # This happens if start_epoch is 0 or the file history is very short/empty\n",
        "                    print(\"No previous history needs to be loaded (start_epoch is 0 or history file is empty/short).\")\n",
        "\n",
        "            else: # valid_load_successful == False due to initial file format check failure\n",
        "                 print(\"Metrics file has an invalid initial structure. Starting history fresh.\")\n",
        "                 all_metrics = {key: [] for key in expected_keys} # Start fresh\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error decoding JSON from {METRICS_FILE}. File might be corrupt. Starting history fresh.\")\n",
        "        all_metrics = {key: [] for key in expected_keys} # Start fresh\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred loading metrics history: {e}. Starting history fresh.\")\n",
        "        all_metrics = {key: [] for key in expected_keys} # Start fresh\n",
        "\n",
        "else:\n",
        "    print(\"Metrics history file not found. Starting history fresh.\")\n",
        "    # If the file does not exist, all_metrics remains the initial dictionary with empty lists.\n",
        "\n",
        "\n",
        "# --- Main Training and Validation Loop ---\n",
        "# Define the interval for performing expensive evaluations (Clinical)\n",
        "evaluation_interval = 3 # Perform full evaluation every 3 epochs\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    print(f\"\\n===== Epoch {epoch+1}/{num_epochs} =====\")\n",
        "    epoch_start_time = time.time() # Record the start time of the current epoch\n",
        "\n",
        "    # --- Progressive Unfreezing ---\n",
        "    # Apply the unfreezing strategy based on the current epoch number\n",
        "    # This function returns the (potentially new) optimizer instance\n",
        "    optimizer = unfreeze_layers(model, epoch, optimizer, INITIAL_LR, progressive_unfreezing_schedule)\n",
        "\n",
        "    # --- Curriculum Learning ---\n",
        "    # Get the subset of the training data for the current epoch\n",
        "    current_train_dataset = get_curriculum_dataset(epoch, train_df, tokenizer,\n",
        "                                                   initial_size=curriculum_learning_schedule[\"initial_size\"],\n",
        "                                                   increment=curriculum_learning_schedule[\"increment\"],\n",
        "                                                   increment_every=curriculum_learning_schedule[\"increment_every_epochs\"])\n",
        "    # Create the DataLoader for the current training dataset subset\n",
        "    # Use more workers/pin_memory if resources allow for faster data loading\n",
        "    train_dataloader = DataLoader(current_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Store the size of the training sample used in this epoch\n",
        "    # This is always recorded\n",
        "    all_metrics['sample_sizes'].append(len(current_train_dataset))\n",
        "\n",
        "\n",
        "    # --- Training Phase ---\n",
        "    model.train() # Set the model to training mode\n",
        "    total_train_loss = 0 # Variable to accumulate training loss over the epoch\n",
        "    optimizer.zero_grad() # Zero the gradients at the beginning of the epoch or accumulation step\n",
        "\n",
        "    # Use tqdm for a progress bar over the training batches\n",
        "    progress_bar_train = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Training\", leave=False)\n",
        "    for idx, batch in enumerate(progress_bar_train):\n",
        "        # Move batch data to the appropriate device (GPU/CPU)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # --- Forward Pass with Mixed Precision (AMP) ---\n",
        "        # autocast enables automatic mixed precision, which speeds up training\n",
        "        with autocast(): # Note: Update to torch.amp.autocast('cuda', ...) for newer PyTorch\n",
        "            # Perform the forward pass, calculate loss\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels # Labels are used internally to calculate the loss\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            # Scale the loss by the gradient accumulation steps\n",
        "            # This is necessary because gradients are summed over multiple batches\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "\n",
        "        # --- Backward Pass with GradScaler ---\n",
        "        # Scale the loss before backward pass in AMP\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # --- Optimizer Step (with Gradient Accumulation) ---\n",
        "        # Perform optimizer step only after accumulating gradients over several batches\n",
        "        # Or perform a step for the last batch even if it's less than accumulation steps\n",
        "        if (idx + 1) % gradient_accumulation_steps == 0 or (idx + 1) == len(train_dataloader):\n",
        "            # Optional: Gradient clipping to prevent exploding gradients\n",
        "            # scaler.unscale_(optimizer) # Unscale gradients before clipping\n",
        "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Perform optimizer step using the scaled gradients\n",
        "            scaler.step(optimizer)\n",
        "            # Update the scale for the next iteration\n",
        "            scaler.update()\n",
        "            # Zero the gradients after the optimizer step\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Accumulate the loss (undo the scaling by accumulation steps for accurate logging)\n",
        "        total_train_loss += loss.item() * gradient_accumulation_steps\n",
        "        # Update the progress bar with the current loss\n",
        "        progress_bar_train.set_postfix({'loss': loss.item() * gradient_accumulation_steps})\n",
        "\n",
        "        # Clean up batch variables and clear GPU cache to save memory\n",
        "        del input_ids, attention_mask, labels, outputs, loss\n",
        "        if device == torch.device('cuda'):\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect() # Collect garbage\n",
        "\n",
        "    # Calculate the average training loss for the epoch\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader) # Divide by number of batches\n",
        "    print(f\"Epoch {epoch+1} Average Training Loss: {avg_train_loss:.4f}\")\n",
        "    # Store the average training loss in the metrics history\n",
        "    # This is always recorded\n",
        "    all_metrics['train_loss'].append(avg_train_loss)\n",
        "\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    total_val_loss = 0 # Variable to accumulate validation loss\n",
        "    # Lists to store generated summaries, references, and raw inputs for evaluation\n",
        "    val_references = [] # TF-IDF targets for ROUGE/BLEU\n",
        "    val_hypotheses = [] # Model generated summaries\n",
        "    val_raw_inputs = [] # Original texts for Clinical (Entity) metrics\n",
        "\n",
        "    print(f\"\\nRunning Validation for Epoch {epoch+1}...\")\n",
        "    # Use tqdm for a progress bar over the validation batches\n",
        "    progress_bar_val = tqdm(val_dataloader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
        "\n",
        "    # Disable gradient calculation during validation to save memory and speed up\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar_val:\n",
        "            # Move batch data to the appropriate device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            # Get raw texts from the batch (these are not tensors)\n",
        "            raw_input_texts = batch['raw_input']\n",
        "            raw_target_texts = batch['raw_target']\n",
        "\n",
        "            # --- Calculate Validation Loss ---\n",
        "            # Use mixed precision for validation loss calculation as well\n",
        "            with autocast(): # Note: Update to torch.amp.autocast('cuda', ...) for newer PyTorch\n",
        "                 # Perform forward pass to calculate loss\n",
        "                 outputs = model(\n",
        "                     input_ids=input_ids,\n",
        "                     attention_mask=attention_mask,\n",
        "                     labels=labels\n",
        "                 )\n",
        "                 loss = outputs.loss\n",
        "            # Accumulate the validation loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "\n",
        "            # --- Generate Summaries ---\n",
        "            # Generate summaries from the input texts using beam search (or other decoding strategies)\n",
        "            # This is done for all validation batches to calculate standard metrics\n",
        "            # Use autocast here if generation benefits from mixed precision (check performance)\n",
        "            # with autocast():\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                # Use generation parameters defined in Configuration cell\n",
        "                max_length=generation_parameters[\"max_length\"],\n",
        "                num_beams=generation_parameters[\"num_beams\"],\n",
        "                length_penalty=generation_parameters[\"length_penalty\"],\n",
        "                early_stopping=generation_parameters[\"early_stopping\"],\n",
        "                no_repeat_ngram_size=generation_parameters[\"no_repeat_ngram_size\"]\n",
        "            )\n",
        "\n",
        "            # Decode the generated token IDs back into human-readable text\n",
        "            hypotheses_batch = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            # Store the generated summaries, raw targets, and raw inputs for metric calculation later\n",
        "            val_hypotheses.extend(hypotheses_batch)\n",
        "            val_references.extend(raw_target_texts) # TF-IDF targets are references for standard metrics\n",
        "            val_raw_inputs.extend(raw_input_texts)  # Original inputs are references for clinical metrics\n",
        "\n",
        "\n",
        "            # Clean up batch variables and clear GPU cache\n",
        "            del input_ids, attention_mask, labels, raw_input_texts, raw_target_texts, outputs, loss, generated_ids\n",
        "            if device == torch.device('cuda'):\n",
        "                torch.cuda.empty_cache()\n",
        "            gc.collect() # Collect garbage\n",
        "\n",
        "\n",
        "    # Calculate the average validation loss for the epoch\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader) # Divide by number of batches\n",
        "    print(f\"Epoch {epoch+1} Average Validation Loss: {avg_val_loss:.4f}\")\n",
        "    # Store the average validation loss in the metrics history\n",
        "    # This is always recorded\n",
        "    all_metrics['val_loss'].append(avg_val_loss)\n",
        "\n",
        "\n",
        "    # --- Calculate Standard Validation Metrics (Always) ---\n",
        "    print(\"\\nCalculating Standard Validation Metrics (ROUGE, BLEU)...\")\n",
        "    # Calculate standard metrics comparing generated summaries to TF-IDF targets\n",
        "    metrics_std = calculate_metrics(val_references, val_hypotheses)\n",
        "    print(f\"Std Metrics - R1: {metrics_std['rouge-1']:.4f}, R2: {metrics_std['rouge-2']:.4f}, RL: {metrics_std['rouge-l']:.4f}, B: {metrics_std['bleu']:.4f}\")\n",
        "\n",
        "    # Store Standard Metrics (Always)\n",
        "    all_metrics['rouge-1'].append(metrics_std['rouge-1'])\n",
        "    all_metrics['rouge-2'].append(metrics_std['rouge-2'])\n",
        "    all_metrics['rouge-l'].append(metrics_std['rouge-l'])\n",
        "    all_metrics['bleu'].append(metrics_std['bleu'])\n",
        "\n",
        "\n",
        "    # --- Conditional Calculation of Clinical Metrics ---\n",
        "    # Check if the current epoch is an interval where we perform the full evaluation\n",
        "    if (epoch + 1) % evaluation_interval == 0:\n",
        "        print(f\"\\nEpoch {epoch+1}: Performing full evaluation (Clinical)...\")\n",
        "\n",
        "        # Calculate Clinical Metrics (Entity Overlap)\n",
        "        print(\"Calculating Clinical Validation Metrics (Entity Overlap)...\")\n",
        "        metrics_clin = calculate_clinical_metrics(val_raw_inputs, val_hypotheses)\n",
        "        print(f\"Clinical Metrics - ER: {metrics_clin['entity_recall']:.4f}, EP: {metrics_clin['entity_precision']:.4f}, EF1: {metrics_clin['entity_f1']:.4f}\")\n",
        "\n",
        "        # Store Clinical Metrics for this epoch\n",
        "        all_metrics['entity_recall'].append(metrics_clin['entity_recall'])\n",
        "        all_metrics['entity_precision'].append(metrics_clin['entity_precision'])\n",
        "        all_metrics['entity_f1'].append(metrics_clin['entity_f1'])\n",
        "\n",
        "    else:\n",
        "        # If this is not an evaluation interval epoch, append placeholder values\n",
        "        print(f\"\\nEpoch {epoch+1}: Skipping full evaluation (Clinical). Appending placeholder values.\")\n",
        "        all_metrics['entity_recall'].append(0.0) # Or use None, but 0.0 might be simpler for plotting\n",
        "        all_metrics['entity_precision'].append(0.0)\n",
        "        all_metrics['entity_f1'].append(0.0)\n",
        "\n",
        "\n",
        "    # --- Record Epoch Runtime ---\n",
        "    epoch_end_time = time.time() # Record the end time of the current epoch\n",
        "    epoch_duration = epoch_end_time - epoch_start_time # Calculate epoch duration\n",
        "    all_metrics['epoch_runtime_seconds'].append(epoch_duration) # Store duration in history\n",
        "    print(f\"Epoch {epoch+1} took {epoch_duration:.2f} seconds ({epoch_duration/60:.2f} minutes).\")\n",
        "\n",
        "\n",
        "    # --- Checkpoint Saving ---\n",
        "    # Combine current epoch metrics for saving with the checkpoint (only include computed metrics)\n",
        "    # If conditional evaluation happened, include all metrics; otherwise, only standard + loss\n",
        "    if (epoch + 1) % evaluation_interval == 0:\n",
        "         current_epoch_metrics = {**metrics_std, **metrics_clin,\n",
        "                                  'train_loss': avg_train_loss, 'val_loss': avg_val_loss, 'epoch': epoch}\n",
        "    else:\n",
        "         current_epoch_metrics = {**metrics_std,\n",
        "                                  'train_loss': avg_train_loss, 'val_loss': avg_val_loss, 'epoch': epoch,\n",
        "                                  'entity_recall': 0.0, 'entity_precision': 0.0, 'entity_f1': 0.0} # Add clinical placeholders too\n",
        "\n",
        "\n",
        "    # Save the latest model checkpoint after each epoch\n",
        "    save_checkpoint(model, optimizer, epoch, current_epoch_metrics, latest_model_path)\n",
        "\n",
        "    # Determine the current metric value used for tracking the \"best\" model\n",
        "    # The code currently uses ROUGE-L from standard metrics (calculated every epoch)\n",
        "    current_metric_value = metrics_std['rouge-l']\n",
        "\n",
        "    # Check if the current model is the best seen so far based on best_val_metric\n",
        "    if current_metric_value > best_val_metric:\n",
        "        best_val_metric = current_metric_value # Update the best metric value\n",
        "        best_model_epoch = epoch # Store the epoch number of the new best model\n",
        "        print(f\"\\nNew best model found! Metric: {best_val_metric:.4f} at epoch {epoch+1}\")\n",
        "        # Save a separate checkpoint specifically for the best model\n",
        "        # Save the full set of metrics calculated in this epoch with the best model checkpoint\n",
        "        save_checkpoint(model, optimizer, epoch, current_epoch_metrics, best_model_path) # Save full metrics with best model\n",
        "    else:\n",
        "         # Ensure best_model_epoch is correctly reflected if a checkpoint was loaded initially\n",
        "         if best_model_epoch == -1: # Case where no best model was found initially\n",
        "              print(f\"Current model metric ({current_metric_value:.4f}). No best model found yet.\")\n",
        "         else:\n",
        "              print(f\"Current model metric ({current_metric_value:.4f}) is not better than best ({best_val_metric:.4f} at epoch {best_model_epoch+1}).\")\n",
        "\n",
        "\n",
        "    # Save a backup checkpoint periodically (e.g., every 5 epochs)\n",
        "    backup_interval = 5 # Define backup interval\n",
        "    if (epoch + 1) % backup_interval == 0:\n",
        "        backup_path = os.path.join(CHECKPOINT_DIR, f\"backup_epoch_{epoch+1}.pt\")\n",
        "        save_checkpoint(model, optimizer, epoch, current_epoch_metrics, backup_path)\n",
        "\n",
        "\n",
        "    # Save the entire metrics history to the JSON file after each epoch\n",
        "    # This happens every epoch to ensure consistent list lengths\n",
        "    save_metrics(all_metrics, METRICS_FILE)\n",
        "\n",
        "\n",
        "    # Clean up memory before the next epoch\n",
        "    del current_train_dataset # Delete the dataset object to free memory\n",
        "    gc.collect()\n",
        "    if device == torch.device('cuda'): torch.cuda.empty_cache()\n",
        "\n",
        "# Print message after training loop completes\n",
        "print(\"\\n===== Training Completed =====\")\n",
        "\n",
        "# Calculate and print the total training duration (excluding time spent on crashes/restarts)\n",
        "# This sum includes the runtime of each successfully completed epoch\n",
        "total_training_seconds = sum(all_metrics.get('epoch_runtime_seconds', []))\n",
        "total_training_minutes = total_training_seconds / 60.0\n",
        "print(f\"Total training duration (successful epochs): {total_training_minutes:.2f} minutes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdylSQpo-FNr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "91d7ac470c7b4652944d1948f50798b6",
            "8c41bb9d545d403b9fffd1f60869fb00",
            "039b652085fa4582bf987b0ee7847327",
            "7ddf1796ce7d44e7977e73e25cedfbf6",
            "73b5b27a30834537a2969f30e3ffd6d9",
            "d342324f8e254ceb961ecc6c2ef4f672",
            "e860eaf6721047b2a632deb02b787d2d",
            "c392a9ac2f524c2d9f80047aff3ad137",
            "a10b7fbd50fe46b186b85058c534fb58",
            "6b94b75fbc4b4df59a221f23a9262d36",
            "3d23b86428614825b850b43aa21506f3"
          ]
        },
        "outputId": "9f1f4750-3b69-4ac3-e609-d6b13dee30c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Evaluating on Test Set using Best Model =====\n",
            "Loading best model from /content/drive/MyDrive/BioBart_TFIDF_Structured/best_model.pt for final evaluation...\n",
            "Loading checkpoint from /content/drive/MyDrive/BioBart_TFIDF_Structured/best_model.pt...\n",
            "Model state loaded.\n",
            "Checkpoint loaded successfully. Resuming training from epoch 15\n",
            "Running inference on the test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing:   0%|          | 0/1965 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91d7ac470c7b4652944d1948f50798b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# (Cell 13) Final Test Set Evaluation\n",
        "\n",
        "print(\"\\n===== Evaluating on Test Set using Best Model =====\")\n",
        "test_eval_start_time = time.time() # Record the start time of test evaluation\n",
        "\n",
        "# Load the best performing model for the final evaluation\n",
        "# Prioritize the best model checkpoint\n",
        "best_model_path = os.path.join(DRIVE_PATH, \"best_model.pt\")\n",
        "latest_model_path = os.path.join(DRIVE_PATH, \"latest_model.pt\")\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"Loading best model from {best_model_path} for final evaluation...\")\n",
        "    # Load the model state dictionary. Pass None for the optimizer as it's not needed for evaluation.\n",
        "    model, _, _, _ = load_checkpoint(best_model_path, model, None, device)\n",
        "elif os.path.exists(latest_model_path):\n",
        "    print(\"Warning: Best model checkpoint not found. Evaluating with the latest model.\")\n",
        "    # Load the latest model checkpoint if the best is not available\n",
        "    model, _, _, _ = load_checkpoint(latest_model_path, model, None, device)\n",
        "else:\n",
        "    # If neither checkpoint is found, print an error and exit or handle appropriately\n",
        "    print(\"Error: No model checkpoint found (best or latest) for final evaluation.\")\n",
        "    # exit() # Exit the script\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Lists to store generated summaries, references, and raw inputs for test evaluation\n",
        "test_references = [] # TF-IDF Targets for ROUGE/BLEU\n",
        "test_hypotheses = [] # Model generated summaries\n",
        "test_raw_inputs = [] # Original Texts for Clinical (Entity) metrics\n",
        "\n",
        "print(\"Running inference on the test set...\")\n",
        "# Use tqdm for a progress bar over the test batches\n",
        "progress_bar_test = tqdm(test_dataloader, desc=\"Testing\")\n",
        "\n",
        "# Disable gradient calculation during inference\n",
        "with torch.no_grad():\n",
        "    for batch in progress_bar_test:\n",
        "        # Move batch data to the appropriate device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        # Get raw texts from the batch (these are not tensors)\n",
        "        raw_input_texts = batch['raw_input']\n",
        "        raw_target_texts = batch['raw_target']\n",
        "\n",
        "        # --- Generate Summaries for Test Samples ---\n",
        "        # Use the same generation parameters as used during validation\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=generation_parameters[\"max_length\"],\n",
        "            num_beams=generation_parameters[\"num_beams\"],\n",
        "            length_penalty=generation_parameters[\"length_penalty\"],\n",
        "            early_stopping=generation_parameters[\"early_stopping\"],\n",
        "            no_repeat_ngram_size=generation_parameters[\"no_repeat_ngram_size\"]\n",
        "        )\n",
        "\n",
        "        # Decode the generated token IDs back into human-readable text\n",
        "        hypotheses_batch = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "        # Store the generated summaries, raw targets, and raw inputs for metric calculation later\n",
        "        test_hypotheses.extend(hypotheses_batch)\n",
        "        test_references.extend(raw_target_texts) # TF-IDF targets are references for standard metrics\n",
        "        test_raw_inputs.extend(raw_input_texts)  # Original inputs are references for clinical metrics\n",
        "\n",
        "\n",
        "        # Clean up batch variables and clear GPU cache\n",
        "        del input_ids, attention_mask, raw_input_texts, raw_target_texts, generated_ids\n",
        "        if device == torch.device('cuda'):\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect() # Collect garbage\n",
        "\n",
        "\n",
        "# --- Record Test Evaluation Runtime ---\n",
        "test_eval_end_time = time.time() # Record the end time of test evaluation\n",
        "test_eval_duration_seconds = test_eval_end_time - test_eval_start_time\n",
        "test_eval_duration_minutes = test_eval_duration_seconds / 60.0\n",
        "print(f\"Test set evaluation duration: {test_eval_duration_minutes:.2f} minutes.\")\n",
        "\n",
        "\n",
        "# --- Calculate Final Test Metrics ---\n",
        "print(\"\\nCalculating Final Test Metrics...\")\n",
        "\n",
        "# Calculate standard metrics (ROUGE, BLEU) comparing generated summaries to TF-IDF targets\n",
        "final_metrics_std = calculate_metrics(test_references, test_hypotheses)\n",
        "print(f\"Final Standard Metrics - R1: {final_metrics_std['rouge-1']:.4f}, R2: {final_metrics_std['rouge-2']:.4f}, RL: {final_metrics_std['rouge-l']:.4f}, B: {final_metrics_std['bleu']:.4f}\")\n",
        "\n",
        "# Calculate clinical metrics (Entity Overlap) comparing generated summaries to original raw inputs\n",
        "final_metrics_clin = calculate_clinical_metrics(test_raw_inputs, test_hypotheses)\n",
        "print(f\"Final Clinical Metrics - ER: {final_metrics_clin['entity_recall']:.4f}, EP: {final_metrics_clin['entity_precision']:.4f}, EF1: {final_metrics_clin['entity_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSuftXHc-WL8"
      },
      "outputs": [],
      "source": [
        "# (Cell 14) Save Final Results and Model\n",
        "\n",
        "# --- Save Final Results Summary ---\n",
        "# Combine all final test metrics and relevant information into a summary dictionary\n",
        "final_results_summary = {\n",
        "    'test_metrics_standard': final_metrics_std,\n",
        "    'test_metrics_clinical': final_metrics_clin,\n",
        "    'training_history_file': METRICS_FILE, # Path to the full training history JSON\n",
        "    'training_config_file': CONFIG_FILE, # Path to the training configuration JSON\n",
        "    'qualitative_examples_file': QUALITATIVE_EXAMPLES_FILE, # Path to the qualitative examples JSON\n",
        "    'best_model_epoch': best_model_epoch + 1 if best_model_epoch != -1 else 'N/A', # +1 for human-readable epoch number\n",
        "    'best_model_validation_metric': best_val_metric, # The best validation metric achieved\n",
        "    'final_training_samples_used': all_metrics['sample_sizes'][-1] if all_metrics['sample_sizes'] else 'N/A', # Size of training data in the last epoch\n",
        "    'total_training_duration_minutes': total_training_minutes, # Total time spent in training loop\n",
        "    'test_evaluation_duration_minutes': test_eval_duration_minutes # Total time spent evaluating on test set\n",
        "}\n",
        "\n",
        "print(f\"\\nSaving final results summary to {FINAL_RESULTS_FILE}...\")\n",
        "try:\n",
        "    # Save the summary dictionary to a JSON file\n",
        "    with open(FINAL_RESULTS_FILE, 'w', encoding='utf-8') as f:\n",
        "        json.dump(final_results_summary, f, ensure_ascii=False, indent=4)\n",
        "    print(\"Final results summary saved successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving final results summary: {e}\")\n",
        "\n",
        "# --- Save the Final Trained Model ---\n",
        "# Save the complete fine-tuned model using save_pretrained\n",
        "# This saves the model's architecture and weights in a format that can be easily reloaded\n",
        "print(f\"\\nSaving the complete fine-tuned model (from best epoch) to {FINAL_MODEL_PATH}...\")\n",
        "try:\n",
        "    # Ensure the directory for the final model exists\n",
        "    os.makedirs(FINAL_MODEL_PATH, exist_ok=True)\n",
        "    model.save_pretrained(FINAL_MODEL_PATH)\n",
        "    # It's good practice to also save the tokenizer with the model,\n",
        "    # though it was already saved earlier, doing it again here ensures they are together.\n",
        "    tokenizer.save_pretrained(FINAL_MODEL_PATH)\n",
        "    print(\"Final model and tokenizer saved successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving final model: {e}\")\n",
        "\n",
        "\n",
        "# --- Save Qualitative Examples ---\n",
        "# Select a small number of random examples from the test set results\n",
        "print(f\"\\nSelecting and saving qualitative examples to {QUALITATIVE_EXAMPLES_FILE}...\")\n",
        "num_examples_to_save = 10 # Define how many examples to save\n",
        "saved_examples = [] # List to store the selected example dictionaries\n",
        "\n",
        "# Ensure there are test samples available\n",
        "if len(test_raw_inputs) > 0:\n",
        "    # Select random indices from the range of test samples\n",
        "    # Use min() to handle cases where test set size is less than num_examples_to_save\n",
        "    selected_indices = random.sample(range(len(test_raw_inputs)), min(num_examples_to_save, len(test_raw_inputs)))\n",
        "\n",
        "    # Iterate through the selected indices and create a dictionary for each example\n",
        "    for idx in selected_indices:\n",
        "        saved_examples.append({\n",
        "            \"original_input\": test_raw_inputs[idx], # The original full report text\n",
        "            \"tfidf_target\": test_references[idx], # The TF-IDF extractive summary (training target)\n",
        "            \"generated_summary\": test_hypotheses[idx] # The summary generated by the model\n",
        "        })\n",
        "\n",
        "    try:\n",
        "        # Save the list of example dictionaries to a JSON file\n",
        "        with open(QUALITATIVE_EXAMPLES_FILE, 'w', encoding='utf-8') as f:\n",
        "            json.dump(saved_examples, f, ensure_ascii=False, indent=4)\n",
        "        print(f\"{len(saved_examples)} qualitative examples saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving qualitative examples: {e}\")\n",
        "else:\n",
        "    print(\"No test samples available to save qualitative examples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyVR7lLV-JXz"
      },
      "outputs": [],
      "source": [
        "# (Cell 15) Example Inference\n",
        "\n",
        "# --- Example Inference Function ---\n",
        "# This function demonstrates how to use the fine-tuned model to generate a summary for a new raw input text.\n",
        "# It applies the same preprocessing steps (section tokens, length token) as used during training.\n",
        "\n",
        "def generate_summary(input_text_raw, model, tokenizer, device, max_gen_length=generation_parameters[\"max_length\"]):\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # --- Apply Preprocessing Steps as done during training (Crucial) ---\n",
        "    # The inference input MUST be formatted consistently with the training input.\n",
        "\n",
        "    # 1. Add Section Tokens\n",
        "    section_aware_text = add_section_tokens(input_text_raw, section_headers_map=SECTION_HEADERS, all_headers_regex=ALL_HEADERS_REGEX)\n",
        "\n",
        "\n",
        "    # Using Option A for this example: prepend a default length token.\n",
        "    # Choose one of your defined length control tokens.\n",
        "    control_token_for_inference = \"<SUM_MEDIUM>\" # Example default for inference\n",
        "\n",
        "\n",
        "    # 2. Create the final formatted input text\n",
        "    # The format must match training: <LENGTH_TOKEN> <SECTION_AWARE_TEXT>\n",
        "    final_input_text = control_token_for_inference + \" \" + section_aware_text\n",
        "\n",
        "    # Add a basic check for empty input text after processing\n",
        "    if not final_input_text.strip():\n",
        "         print(\"Warning: Input text is empty after preprocessing. Cannot generate summary.\")\n",
        "         return \"Error: Empty input text after preprocessing.\"\n",
        "\n",
        "\n",
        "    # --- Tokenize the preprocessed input text ---\n",
        "    encoding = tokenizer(\n",
        "        final_input_text,\n",
        "        max_length=MAX_INPUT_LENGTH, # Use the same max input length as training\n",
        "        padding='max_length', # Pad to max_length\n",
        "        truncation=True, # Truncate if longer than max_length\n",
        "        return_tensors=\"pt\" # Return PyTorch tensors\n",
        "    )\n",
        "\n",
        "    # Move tokenized input to the appropriate device\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "\n",
        "    summary_text = \"Error generating summary.\" # Default error message in case of failure\n",
        "\n",
        "    # --- Generate Summary using the model ---\n",
        "    with torch.no_grad(): # Disable gradient calculation\n",
        "        try:\n",
        "            # Generate summary using the same parameters as validation/test evaluation\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=max_gen_length, # Use the specified max generation length\n",
        "                num_beams=generation_parameters[\"num_beams\"],\n",
        "                length_penalty=generation_parameters[\"length_penalty\"],\n",
        "                early_stopping=generation_parameters[\"early_stopping\"],\n",
        "                no_repeat_ngram_size=generation_parameters[\"no_repeat_ngram_size\"]\n",
        "            )\n",
        "            # Decode the generated IDs back to text, skipping special tokens\n",
        "            summary_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during summary generation: {e}\")\n",
        "\n",
        "\n",
        "    # Clean up tensors and clear GPU cache\n",
        "    del input_ids, attention_mask, encoding\n",
        "    if device == torch.device('cuda'):\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect() # Collect garbage\n",
        "\n",
        "    return summary_text\n",
        "\n",
        "\n",
        "# --- Example Usage of Inference Function ---\n",
        "print(\"\\n--- Example Inference ---\")\n",
        "\n",
        "# Define a sample raw input text (like a new radiology report)\n",
        "sample_text_raw = \"\"\"\n",
        "INDICATION: Evaluate for pneumonia.\n",
        "TECHNIQUE: Portable anteroposterior chest X-ray.\n",
        "FINDINGS: The lungs are clear bilaterally without evidence of consolidation, effusion, or pneumothorax. The heart size is normal. Mediastinal and hilar contours are unremarkable. Visualized osseous structures are intact.\n",
        "IMPRESSION: No acute cardiopulmonary abnormality.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Generate a summary for the sample raw text\n",
        "generated_text = generate_summary(sample_text_raw, model, tokenizer, device)\n",
        "\n",
        "# Print the original text and the generated summary\n",
        "print(f\"Input Text (Raw):\\n{sample_text_raw}\\n\")\n",
        "print(f\"Generated Summary:\\n{generated_text}\")\n",
        "\n",
        "print(\"\\n===== Script Finished =====\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec7b1af1152343779c90f54bd2282d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a1fea910afb4313be0983b9d804bd17",
              "IPY_MODEL_393fafede89246d3a7d6777becf5416e",
              "IPY_MODEL_db19c56364204bd590230adb7107f17b"
            ],
            "layout": "IPY_MODEL_406f9661028e4c2b8156efaa52c5f095"
          }
        },
        "8a1fea910afb4313be0983b9d804bd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3172cb6ac6624203a2d69848db609d7c",
            "placeholder": "",
            "style": "IPY_MODEL_a97c67e68e4a4544a0d89a932fa4dd87",
            "value": "100%"
          }
        },
        "393fafede89246d3a7d6777becf5416e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b10b6d09809423c923fbbfae74f8e5c",
            "max": 104995,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bb56b5ee7304a2c9474644679d178de",
            "value": 104995
          }
        },
        "db19c56364204bd590230adb7107f17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19453ff4e85541d29f0b8330d58f5567",
            "placeholder": "",
            "style": "IPY_MODEL_9a342f909c8d4844a389f0bcade1606a",
            "value": "104995/104995[00:03&lt;00:00,43849.23it/s]"
          }
        },
        "406f9661028e4c2b8156efaa52c5f095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3172cb6ac6624203a2d69848db609d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97c67e68e4a4544a0d89a932fa4dd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b10b6d09809423c923fbbfae74f8e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bb56b5ee7304a2c9474644679d178de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19453ff4e85541d29f0b8330d58f5567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a342f909c8d4844a389f0bcade1606a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f714bdc18d34e2382aff9860f04292c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c004c7d7aaa4a84b1749d651d0260e9",
              "IPY_MODEL_d58d328cc3a74bef8d8493b947902d21",
              "IPY_MODEL_107fff78e068443ca55f28b35c2649b2"
            ],
            "layout": "IPY_MODEL_2530011ec3584100beacb2d43891f77b"
          }
        },
        "5c004c7d7aaa4a84b1749d651d0260e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95be3333d1d54976a0f6e93713591de2",
            "placeholder": "",
            "style": "IPY_MODEL_1b645951eab649d9bf4357a70fe24921",
            "value": "100%"
          }
        },
        "d58d328cc3a74bef8d8493b947902d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0d89b9b30a0467c8557db0889b089c3",
            "max": 104783,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a515449b26cf4cbd95b99c5a351a5cf4",
            "value": 104783
          }
        },
        "107fff78e068443ca55f28b35c2649b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f01842412e24e09a7858efddfac504d",
            "placeholder": "",
            "style": "IPY_MODEL_b62b4f5ee44e43c6a1baeeebc1450160",
            "value": "104783/104783[00:01&lt;00:00,60072.30it/s]"
          }
        },
        "2530011ec3584100beacb2d43891f77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95be3333d1d54976a0f6e93713591de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b645951eab649d9bf4357a70fe24921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0d89b9b30a0467c8557db0889b089c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a515449b26cf4cbd95b99c5a351a5cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f01842412e24e09a7858efddfac504d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b62b4f5ee44e43c6a1baeeebc1450160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e098ce4026ab4df186bd2551af8e3047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb75e5a900f34bdb997a22be3557183b",
              "IPY_MODEL_89c8be812473417caf9532eaaa052395",
              "IPY_MODEL_2d38a2dcbafd42a4af8605433260f51c"
            ],
            "layout": "IPY_MODEL_eb38bb5ffdeb438a8a6969fd892d359b"
          }
        },
        "fb75e5a900f34bdb997a22be3557183b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16f2cbfc4d2747a6818a66b558c82e38",
            "placeholder": "",
            "style": "IPY_MODEL_91a07466694747f49a7ca92c42613e1e",
            "value": "100%"
          }
        },
        "89c8be812473417caf9532eaaa052395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283e700a6f9641eda3982e79c5fea687",
            "max": 104783,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afe8bc2824e44c38bf9337e4192a8263",
            "value": 104783
          }
        },
        "2d38a2dcbafd42a4af8605433260f51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a94100f7465042cc9c7260160b0ef9d5",
            "placeholder": "",
            "style": "IPY_MODEL_456993ba73714e5fa05fa4b116cb51ea",
            "value": "104783/104783[03:51&lt;00:00,513.66it/s]"
          }
        },
        "eb38bb5ffdeb438a8a6969fd892d359b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f2cbfc4d2747a6818a66b558c82e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a07466694747f49a7ca92c42613e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "283e700a6f9641eda3982e79c5fea687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe8bc2824e44c38bf9337e4192a8263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a94100f7465042cc9c7260160b0ef9d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456993ba73714e5fa05fa4b116cb51ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "350530365d434fb5a6f4db62e77a70e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71abcce11e7647d5801f7e0acad9ba8d",
              "IPY_MODEL_f4dbf7f0ce3d45a2bbcd3a8a6492a8b6",
              "IPY_MODEL_38f46293d00342578dcaa8341e62a41f"
            ],
            "layout": "IPY_MODEL_6e4fc5c5034448ea8aa1e570a30b4e5a"
          }
        },
        "71abcce11e7647d5801f7e0acad9ba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_959ecb1a3f1c42a5a7542d2e51eec7cc",
            "placeholder": "",
            "style": "IPY_MODEL_191e47eeaf2840fa8e0c918d36a35f21",
            "value": "100%"
          }
        },
        "f4dbf7f0ce3d45a2bbcd3a8a6492a8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c120cee1d80437d841958069d179d95",
            "max": 104783,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_976b24bf3d534b78b69d4c55e002559e",
            "value": 104783
          }
        },
        "38f46293d00342578dcaa8341e62a41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9d16952cdf41a38bce35d199df3975",
            "placeholder": "",
            "style": "IPY_MODEL_be388223ce8a40d392a570cbc7d434d6",
            "value": "104783/104783[00:04&lt;00:00,16510.25it/s]"
          }
        },
        "6e4fc5c5034448ea8aa1e570a30b4e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959ecb1a3f1c42a5a7542d2e51eec7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191e47eeaf2840fa8e0c918d36a35f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c120cee1d80437d841958069d179d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "976b24bf3d534b78b69d4c55e002559e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd9d16952cdf41a38bce35d199df3975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be388223ce8a40d392a570cbc7d434d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e304d861011148349ed242d3aeb5c7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd538c3d760e428a8f8eaf3f8b9e58b2",
              "IPY_MODEL_951a3eebf7524f6fa0f8b5730fa4f96c",
              "IPY_MODEL_e502a214f02a487eb6e207b48232bd69"
            ],
            "layout": "IPY_MODEL_c41637a5a6d9476bb754de3b270e9d4d"
          }
        },
        "bd538c3d760e428a8f8eaf3f8b9e58b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_162d0860abc147c18eba0a607abecb9d",
            "placeholder": "",
            "style": "IPY_MODEL_fd32603814684cf4bec95d8c79d60a73",
            "value": "tokenizer_config.json:100%"
          }
        },
        "951a3eebf7524f6fa0f8b5730fa4f96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfcfcad16b94435fac2f14c2e9a5aa41",
            "max": 1130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0307de9f65ec457bb1664f3a7bcd6349",
            "value": 1130
          }
        },
        "e502a214f02a487eb6e207b48232bd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7262a47c43ac48a0adb64518648defa6",
            "placeholder": "",
            "style": "IPY_MODEL_992c35ab8fb4453ab948c0c93c5b1660",
            "value": "1.13k/1.13k[00:00&lt;00:00,123kB/s]"
          }
        },
        "c41637a5a6d9476bb754de3b270e9d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "162d0860abc147c18eba0a607abecb9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd32603814684cf4bec95d8c79d60a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfcfcad16b94435fac2f14c2e9a5aa41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0307de9f65ec457bb1664f3a7bcd6349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7262a47c43ac48a0adb64518648defa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992c35ab8fb4453ab948c0c93c5b1660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140a79077a6c450ba6ee27c3ca3691fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_037c1fcafeba42eda09e5eb5c9d533bf",
              "IPY_MODEL_13930fbacbb8497d94d4f18450b893b6",
              "IPY_MODEL_ae879a076cd24c6a96ebc14f2bba5a26"
            ],
            "layout": "IPY_MODEL_0abc418740554de5b6d3842d2f34c8a3"
          }
        },
        "037c1fcafeba42eda09e5eb5c9d533bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed0d5f0f947b471787cfbf9d844f216f",
            "placeholder": "",
            "style": "IPY_MODEL_36c329c363c54a8db7825cfde836ced7",
            "value": "vocab.json:100%"
          }
        },
        "13930fbacbb8497d94d4f18450b893b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e8aff5f32c4b53860844df7f4b089d",
            "max": 1585944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a9b5a315ccd417f95101515219ac6ed",
            "value": 1585944
          }
        },
        "ae879a076cd24c6a96ebc14f2bba5a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63546422a4945638152f008448018c6",
            "placeholder": "",
            "style": "IPY_MODEL_657fb591fefe4893a65efcaae6b5ce9c",
            "value": "1.59M/1.59M[00:00&lt;00:00,2.47MB/s]"
          }
        },
        "0abc418740554de5b6d3842d2f34c8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed0d5f0f947b471787cfbf9d844f216f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c329c363c54a8db7825cfde836ced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3e8aff5f32c4b53860844df7f4b089d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9b5a315ccd417f95101515219ac6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e63546422a4945638152f008448018c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657fb591fefe4893a65efcaae6b5ce9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88a571bb87334ad8b3136fe8c8136ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9e444903dc7479ca7aad336802f78f9",
              "IPY_MODEL_e598ad76ad704259a3e7c825a999ebd3",
              "IPY_MODEL_5df8dfa403d942c5a86c343b8b03c7cf"
            ],
            "layout": "IPY_MODEL_9e61ee7bcff3499493bd3cf237822675"
          }
        },
        "c9e444903dc7479ca7aad336802f78f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af799bb162104b7db88e7f58a2e6bd59",
            "placeholder": "",
            "style": "IPY_MODEL_29316412a6264aae919230d79b514671",
            "value": "merges.txt:100%"
          }
        },
        "e598ad76ad704259a3e7c825a999ebd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1106ab13a0604ac7b7855ff0fe1e9c81",
            "max": 892447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e624939b05e64dbc815df3237f076b67",
            "value": 892447
          }
        },
        "5df8dfa403d942c5a86c343b8b03c7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869316973b24472a899cdae86a93cc44",
            "placeholder": "",
            "style": "IPY_MODEL_f01174c687b14b3fa79fe6af271b5e85",
            "value": "892k/892k[00:06&lt;00:00,147kB/s]"
          }
        },
        "9e61ee7bcff3499493bd3cf237822675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af799bb162104b7db88e7f58a2e6bd59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29316412a6264aae919230d79b514671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1106ab13a0604ac7b7855ff0fe1e9c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e624939b05e64dbc815df3237f076b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "869316973b24472a899cdae86a93cc44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f01174c687b14b3fa79fe6af271b5e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d2a6af2e414e65ac88ba874c093bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acbf1a1a34ea45fcad9dce3425a7d3a2",
              "IPY_MODEL_de9efd74d7014cfa88f3b41b985c8fb3",
              "IPY_MODEL_d7891d15ccef4eda8d570c8bb928ec2d"
            ],
            "layout": "IPY_MODEL_a7c233a9ba3446f2a0720c69ac97a9c7"
          }
        },
        "acbf1a1a34ea45fcad9dce3425a7d3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e85c85ef0b41189a55b38773cca882",
            "placeholder": "",
            "style": "IPY_MODEL_8f911fcffda04be19eaf2a7c58eb1008",
            "value": "special_tokens_map.json:100%"
          }
        },
        "de9efd74d7014cfa88f3b41b985c8fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09247310e211474a83e15b9f30edc803",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_695bb75f52d64db68c5f33eb4e881626",
            "value": 772
          }
        },
        "d7891d15ccef4eda8d570c8bb928ec2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1043df36cbc44582af7f845a1d733733",
            "placeholder": "",
            "style": "IPY_MODEL_8398eb08289f4584a6120ced3eb0c31d",
            "value": "772/772[00:00&lt;00:00,79.3kB/s]"
          }
        },
        "a7c233a9ba3446f2a0720c69ac97a9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e85c85ef0b41189a55b38773cca882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f911fcffda04be19eaf2a7c58eb1008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09247310e211474a83e15b9f30edc803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "695bb75f52d64db68c5f33eb4e881626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1043df36cbc44582af7f845a1d733733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8398eb08289f4584a6120ced3eb0c31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cec478c936c9467abe9ad09d882c0def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3e79fed0e4b46e982b2bf417a123def",
              "IPY_MODEL_206d8e23785d42c8b0c0bafaa8f76a59",
              "IPY_MODEL_e2b58fa6ed544418bfed25d349c44348"
            ],
            "layout": "IPY_MODEL_6f53e6be731a4362a00f38c5e1cd09ab"
          }
        },
        "a3e79fed0e4b46e982b2bf417a123def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad431124930a4cd7928058db5eebfb36",
            "placeholder": "",
            "style": "IPY_MODEL_4df84814bc8f4efab75ef61885c40846",
            "value": "config.json:100%"
          }
        },
        "206d8e23785d42c8b0c0bafaa8f76a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b275d42722d43cd8de40666529bde27",
            "max": 1722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91fd70b7299d485e9c43788fc76d078c",
            "value": 1722
          }
        },
        "e2b58fa6ed544418bfed25d349c44348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1878a86011f54ae4b390976bc4a5b553",
            "placeholder": "",
            "style": "IPY_MODEL_0dfc95974a2343cdb7a6413a61ef3029",
            "value": "1.72k/1.72k[00:00&lt;00:00,183kB/s]"
          }
        },
        "6f53e6be731a4362a00f38c5e1cd09ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad431124930a4cd7928058db5eebfb36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df84814bc8f4efab75ef61885c40846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b275d42722d43cd8de40666529bde27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91fd70b7299d485e9c43788fc76d078c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1878a86011f54ae4b390976bc4a5b553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfc95974a2343cdb7a6413a61ef3029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38d671007f4944e7ad6d4b75f2c6a540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad9a7b0fd1bb4a2881a26f9c6209d387",
              "IPY_MODEL_9ac15ca3f31e4c72b1facb3d9f61d485",
              "IPY_MODEL_2a30e8aeabf84e9090d455194bedef2a"
            ],
            "layout": "IPY_MODEL_2a05f58e51c34829af9bb83e67981692"
          }
        },
        "ad9a7b0fd1bb4a2881a26f9c6209d387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66f8251e74464f6eb9afa680edefbec2",
            "placeholder": "",
            "style": "IPY_MODEL_32c1deafe1d8449aa5811a4e795c9a2c",
            "value": "model.safetensors:100%"
          }
        },
        "9ac15ca3f31e4c72b1facb3d9f61d485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45a3001c0c7d4b41a43f3ab5e2333ccf",
            "max": 665990952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8a55ebfbe7141fb9b12c61a0f2e9b5f",
            "value": 665990952
          }
        },
        "2a30e8aeabf84e9090d455194bedef2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb5d2c379114335974f1cf0fbfc1a76",
            "placeholder": "",
            "style": "IPY_MODEL_ba8b6220ad7344fe93711d1d0e91c576",
            "value": "666M/666M[00:06&lt;00:00,83.1MB/s]"
          }
        },
        "2a05f58e51c34829af9bb83e67981692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f8251e74464f6eb9afa680edefbec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c1deafe1d8449aa5811a4e795c9a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45a3001c0c7d4b41a43f3ab5e2333ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a55ebfbe7141fb9b12c61a0f2e9b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfb5d2c379114335974f1cf0fbfc1a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8b6220ad7344fe93711d1d0e91c576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91d7ac470c7b4652944d1948f50798b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c41bb9d545d403b9fffd1f60869fb00",
              "IPY_MODEL_039b652085fa4582bf987b0ee7847327",
              "IPY_MODEL_7ddf1796ce7d44e7977e73e25cedfbf6"
            ],
            "layout": "IPY_MODEL_73b5b27a30834537a2969f30e3ffd6d9"
          }
        },
        "8c41bb9d545d403b9fffd1f60869fb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d342324f8e254ceb961ecc6c2ef4f672",
            "placeholder": "",
            "style": "IPY_MODEL_e860eaf6721047b2a632deb02b787d2d",
            "value": "Testing:46%"
          }
        },
        "039b652085fa4582bf987b0ee7847327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c392a9ac2f524c2d9f80047aff3ad137",
            "max": 1965,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a10b7fbd50fe46b186b85058c534fb58",
            "value": 903
          }
        },
        "7ddf1796ce7d44e7977e73e25cedfbf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b94b75fbc4b4df59a221f23a9262d36",
            "placeholder": "",
            "style": "IPY_MODEL_3d23b86428614825b850b43aa21506f3",
            "value": "902/1965[1:12:51&lt;1:25:28,4.82s/it]"
          }
        },
        "73b5b27a30834537a2969f30e3ffd6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d342324f8e254ceb961ecc6c2ef4f672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e860eaf6721047b2a632deb02b787d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c392a9ac2f524c2d9f80047aff3ad137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10b7fbd50fe46b186b85058c534fb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b94b75fbc4b4df59a221f23a9262d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d23b86428614825b850b43aa21506f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}